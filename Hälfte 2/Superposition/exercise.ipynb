{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcgAnZZOyBYk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stonehenge0/AI-verstehen-Winteraka-2024-25/blob/main/H%C3%A4lfte%202/Superposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "## Setup (don't read, just run!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7yYsYe32yl9U"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     import google.colab # type: ignore\n",
        "#     IN_COLAB = True\n",
        "# except:\n",
        "#     IN_COLAB = False\n",
        "\n",
        "import os, sys\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "repo = \"ARENA_3.0\"\n",
        "\n",
        "# if IN_COLAB:\n",
        "#     # Install packages\n",
        "#     %pip install jaxtyping\n",
        "#     %pip install transformer_lens\n",
        "#     %pip install git+https://github.com/callummcdougall/eindex.git\n",
        "\n",
        "#     # Code to download the necessary files (e.g. solutions, test funcs)\n",
        "#     if not os.path.exists(f\"/content/{chapter}\"):\n",
        "#         !wget https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
        "#         !unzip /content/main.zip 'ARENA_3.0-main/chapter1_transformer_interp/exercises/*'\n",
        "#         sys.path.append(f\"/content/{repo}-main/{chapter}/exercises\")\n",
        "#         os.remove(\"/content/main.zip\")\n",
        "#         os.rename(f\"{repo}-main/{chapter}\", chapter)\n",
        "#         os.rmdir(f\"{repo}-main\")\n",
        "#         os.chdir(f\"{chapter}/exercises\")\n",
        "# else:\n",
        "#     raise Exception(\"If running from VSCode, you should copy code from the Streamlit page, not the Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "koQM0J3d5DSy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ferri/Daten/Studium/CdE-WA-Machine-Learning/ARENA_3.0/chapter1_transformer_interp/exercises\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Callable, Literal\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "from jaxtyping import Float\n",
        "from torch import Tensor, nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.nn import functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "exercises_dir = Path(f\"../../../ARENA_3.0/{chapter}/exercises\").resolve()\n",
        "section_dir = (exercises_dir / \"part31_superposition_and_saes\").resolve()\n",
        "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
        "print(exercises_dir)\n",
        "\n",
        "import part31_superposition_and_saes.utils as utils\n",
        "import part31_superposition_and_saes.tests as tests\n",
        "from plotly.express import line, imshow\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0zgPVMw0XP"
      },
      "source": [
        "# 1️⃣ TMS: Superposition in a Nonprivileged Basis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utS2IIVc5DSy"
      },
      "source": [
        "## Toy Model setup\n",
        "\n",
        "In this section, we'll be examining & running experiments on the toy model studied in [Anthropic's paper](https://transformer-circuits.pub/2022/toy_model/index.html).\n",
        "\n",
        "You can follow along with the paper from the [Demonstrating Superposition](https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating) section onwards; it will approximately follow the order of the sections in this notebook.\n",
        "\n",
        "This paper presented a very rudimentary model for **bottleneck superposition** - when you try and represent more than $n$ features in a vector space of dimension $n$. The model is as follows:\n",
        "\n",
        "* We take a 5-dimensional input $x$\n",
        "* We map it down into 2D space\n",
        "* We map it back up into 5D space (using the transpose of the first matrix)\n",
        "* We add a bias and ReLU\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "h &= W x \\\\\n",
        "x' &= \\operatorname{ReLU}(W^T h + b)\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlf27-l05DSy"
      },
      "source": [
        "### What's the motivation for this setup?\n",
        "\n",
        "The input $x$ represents our five features (they're uniformly sampled between 0 and 1).\n",
        "\n",
        "Each feature can have **importance** and **sparsity**. Recall our earlier definitions:\n",
        "\n",
        "* **Importance** = how useful is this feature for achieving lower loss?\n",
        "* **Sparsity** = how frequently is it in the input data?\n",
        "\n",
        "This is realised in our toy model as follows:\n",
        "\n",
        "* **Importance** = the coefficient on the weighted mean squared error between the input and output, which we use for training the model\n",
        "    * In other words, our loss function is $L = \\sum_x \\sum_i I_i (x_i - x_i^\\prime)^2$, where $I_i$ is the importance of feature $i$.\n",
        "* **Sparsity** = the probability of the corresponding element in $x$ being zero\n",
        "    * In other words, this affects the way our training data is generated (see the method `generate_batch` in the `Module` class below)\n",
        "    * We often refer to **feature probability** (1 minus sparsity) rather than sparsity\n",
        "\n",
        "The justification for using $W^T W$ is as follows: we can think of $W$ (which is a matrix of shape `(2, 5)`) as a grid of \"overlap values\" between the features and bottleneck dimensions. The values of the 5x5 matrix $W^T W$ are the dot products between the 2D representations of each pair of features. To make this intuition clearer, imagine each of the columns of $W$ were unit vectors, then $W^T W$ would be a matrix of cosine similarities between the features (with diagonal elements equal to 1, because the similarity of a feature with itself is 1). To see this for yourself:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aCnqRWlU5DSy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7449, 0.6152, 0.6283, 1.2672, 1.4758]])\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "coloraxis": "coloraxis",
                  "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
                  "name": "0",
                  "type": "heatmap",
                  "xaxis": "x",
                  "yaxis": "y",
                  "z": [
                    [
                      1,
                      -0.98335433,
                      -0.99977636,
                      -0.23791125,
                      0.97329926
                    ],
                    [
                      -0.98335433,
                      1,
                      0.98697644,
                      0.057470083,
                      -0.9153911
                    ],
                    [
                      -0.99977636,
                      0.98697644,
                      0.99999994,
                      0.2173203,
                      -0.9682281
                    ],
                    [
                      -0.23791125,
                      0.057470083,
                      0.2173203,
                      1.0000001,
                      -0.4545079
                    ],
                    [
                      0.97329926,
                      -0.9153911,
                      -0.9682281,
                      -0.4545079,
                      1
                    ]
                  ]
                }
              ],
              "layout": {
                "coloraxis": {
                  "colorscale": [
                    [
                      0,
                      "#0d0887"
                    ],
                    [
                      0.1111111111111111,
                      "#46039f"
                    ],
                    [
                      0.2222222222222222,
                      "#7201a8"
                    ],
                    [
                      0.3333333333333333,
                      "#9c179e"
                    ],
                    [
                      0.4444444444444444,
                      "#bd3786"
                    ],
                    [
                      0.5555555555555556,
                      "#d8576b"
                    ],
                    [
                      0.6666666666666666,
                      "#ed7953"
                    ],
                    [
                      0.7777777777777778,
                      "#fb9f3a"
                    ],
                    [
                      0.8888888888888888,
                      "#fdca26"
                    ],
                    [
                      1,
                      "#f0f921"
                    ]
                  ]
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Cosine similarities of each pair of 2D feature embeddings"
                },
                "width": 600,
                "xaxis": {
                  "anchor": "y",
                  "constrain": "domain",
                  "domain": [
                    0,
                    1
                  ],
                  "scaleanchor": "y"
                },
                "yaxis": {
                  "anchor": "x",
                  "autorange": "reversed",
                  "constrain": "domain",
                  "domain": [
                    0,
                    1
                  ]
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "t.manual_seed(2)\n",
        "\n",
        "W = t.randn(2, 5)\n",
        "W_normed = W / W.norm(dim=0, keepdim=True)\n",
        "\n",
        "imshow(W_normed.T @ W_normed, title=\"Cosine similarities of each pair of 2D feature embeddings\", width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJv1I4UR5DSz"
      },
      "source": [
        "To put it another way - if the columns of $W$ were orthogonal, then $W^T W$ would be the identity. This can't actually be the case because $W$ is a 2x5 matrix, but its columns can be \"nearly orthgonal\" in the sense of having pairwise cosine similarities close to 0.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "\n",
        "Question - can you prove that $W^T W$ can't be the identity when $W$ is not a square matrix?\n",
        "</summary>\n",
        "\n",
        "Proof #1: the rank of a matrix product $AB$ is upper-bounded by the maximum of the two factors $A$ and $B$. In the case of $W^T W$, both matrices have rank at most 2, so the product has rank at most 2.\n",
        "\n",
        "Proof #2: for any vector $x$, $W^T W x = W^T (Wx)$ is in the span of the columns of $W^T$, which is vector space with rank 2.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ksgl3I5DSz"
      },
      "source": [
        "Another nice thing about using two bottleneck dimensions is that we get to visualise our output! We've got a few helper functions for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1I9jFL3kvw-i"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADgCAYAAAAE5FpSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHrRJREFUeJzt3XtYVHX+B/D3MDqDaAwg9wIvaFqheKEhs0KUwrKL1VrZDbuoiZoGO6x2kfDJpdAFyyT3WRNNu+cjdtkURVyXBMsMM0FWCRc0wBRhuMSMzHx+f7icXwMDDsTMOWfm83qe88ec8z3MB50358z3nPP9KoiIwBiTFTexC2CM9RwHlzEZ4uAyJkMcXMZkiIPLmAxxcBmTIQ4uYzLEwWVMhji4jMkQB5cxGbJrcA8cOIB77rkHwcHBUCgUyMnJ6bb9/v37oVAoOi01NTX2LJMx2bFrcJubmxEREYH169f3aL+ysjJUV1cLi7+/v50qZEye+tnzh99555248847e7yfv78/vLy8+r4gxpyEXYPbW+PGjYPBYEB4eDheffVVTJ48ucu2BoMBBoNBeG02m1FXV4fBgwdDoVA4olzG+gQRobGxEcHBwXBz6/5kWFLBDQoKwoYNGxAZGQmDwYCNGzdiypQpOHToECZMmGB1n7S0NKSmpjq4Usbsp6qqCtdcc023bRSOeh5XoVBgx44dmDlzZo/2i46ORmhoKLZu3Wp1e8cjbkNDA0JDQ1FVVQVPT88/UjJjDqXX6xESEoL6+npoNJpu20rqiGuNVqtFQUFBl9vVajXUanWn9Z6enhxcJku2fMWT/HXc4uJiBAUFiV0GY5Ji1yNuU1MTTp06JbyuqKhAcXExfHx8EBoaiuXLl+Ps2bN47733AABr167FsGHDcMMNN6C1tRUbN27Evn37kJuba88yGZMduwb38OHDiImJEV4nJiYCAOLj47F582ZUV1ejsrJS2G40GpGUlISzZ8/Cw8MDY8eOxd69ey1+BmPMgZ1TjqLX66HRaNDQ0MDfcZms9OSzK/nvuIyxzji4jMkQB5cxGeLgMiZDHFzGZIiDy5gMcXAZkyEOLmMyxMFlTIY4uIzJEAeXMRni4DImQxxcxmSIg8uYDHFwGZMhDi5jMsTBZUyGOLiMyZCkJv0CLk/8NWHCBKjVaowYMQKbN2+2Z4mMyZKkJv2qqKjAjBkzEBMTg+LiYixduhTPPvssdu/ebc8yGZMdSU36tWHDBgwbNgx/+9vfAADXXXcdCgoKkJmZibi4OHuVyZjsSGomg8LCQsTGxlqsi4uLw9KlS7vcp+MUJHq93l7lyYrRaERWVhbKy8sRFhaGhIQEqFQqsctifURSnVM1NTUICAiwWBcQEAC9Xo/ffvvN6j5paWnQaDTCEhIS4ohSJS05ORkeHh544YUX8Pbbb+OFF16Ah4cHkpOTxS6N9RFJBbc3li9fjoaGBmGpqqoSuyRRJScnY/Xq1TCZTBbrTSYTVq9ezeF1EpIKbmBgIGpray3W1dbWwtPTEwMGDLC6j1qtFib4cvWJvoxGIzIyMrptk5GRAaPR6KCKmL1IKriTJk1CXl6exbo9e/Zg0qRJIlUkL1lZWZ2OtB2ZTCZkZWU5qCJmL5Ka9Ou5557D22+/jeTkZDz99NPYt28fPvnkE3z11Vf2LFN2uup4Ki8vt2l/W9sxCSM7ys/PJwCdlvj4eCIiio+Pp+jo6E77jBs3jlQqFQ0fPpyys7N79J4NDQ0EgBoaGvrml5AYnU5HSqXS4t9TqVSSTqejzMxMq//eHZfMzEyxfw1mRU8+u3YNrhicObg6na7bQCYmJnYKdcdFqVSSwWAQ+1dhVvTksyup77isa7Z0PL355pt4/vnnu22TmJjI13OdAAdXJmzteAoNDYVOp4NSqbTYplAooNPpkJ6ebs8ymYNwcGWiJx1P6enpaGlpQWZmJrRaLQAgOjqaQ+tEOLgyERYW1qN2KpUKS5cuxaeffgqFQoH9+/dzb7IT4eDKREJCQqfT346USiUSEhIs1oWGhuKOO+4AAGzatMlu9THH4uDKhEqlQmJiYrdtXnjhBasdT88++ywAIDs7G21tbXapjzkWB1dG0tPTrXY8tbv55putrr/33nvh6+uL6upqfP311/YskTkIB1dmft/xtGjRImRmZgoPDiQmJlp9ikqlUiE+Ph4AsHHjRofWy+xDQUQkdhF9Sa/XQ6PRoKGhwWUeOGhubsbo0aNx5swZvPrqq0hJSenUprS0FNdffz2USiWqqqoQFBQkQqWsOz357PIR1wkMHDhQGDXk9ddfx+nTpzu1ue666zB58mSYTCZs2bLFwRWyvsbBdRKzZs1CTEwMWltbu+zEau+k2rhxI5zsRMvlcHCdhEKhwFtvvQWlUokdO3Zgz549ndrMmjULV111FcrLy/Gvf/1LhCpZX+HgOpHw8HAsXLgQAPD88893emB+4MCBmD17NgDupJI7Dq6TSU1NhZ+fH06cOIF169Z12t5+uvzZZ5/h4sWLji6P9REOrpPx8vLC66+/DuByiKurqy22R0ZGYuzYsTAYDHj//ffFKJH1AQ6uE5ozZw60Wi0aGxuxbNkyi20KhYI7qZwAB9cJubm5CafJ7733Hg4ePGix/bHHHoNarcbRo0dx5MgRMUpkfxAH10lptVo8/fTTAIBFixZZPMvr4+ODBx98EAB3UsmVQ4K7fv16DB06FO7u7oiKisK3337bZdvNmzdDoVBYLO7u7o4o0+m0Dxb/ww8/dApo++nyBx98gObmZjHKY3+A3YP78ccfIzExESkpKThy5AgiIiIQFxeHc+fOdbmPp6cnqqurheW///2vvct0Sv7+/li5ciUA4KWXXkJdXZ2wLTo6GsOHD4der8dnn30mVomst+w8/hVptVpauHCh8NpkMlFwcDClpaVZbZ+dnU0ajabX7+fMg8X1xqVLlyg8PJwAUEJCgsW2VatWEQC65ZZbRKqO/Z5kBoszGo34/vvvLSbycnNzQ2xsLAoLC7vcr6mpCUOGDEFISAjuu+8+HD9+3J5lOrV+/foJHVUbNmxAcXGxsG3OnDlwc3NDQUEBTpw4IVKFrDfsGtzz58/DZDJZncirpqbG6j6jRo3Cpk2bsHPnTmzbtg1msxk333wzzpw5Y7W9wWCAXq+3WJilKVOm4KGHHoLZbMbixYuFS0DBwcGYMWMGAODdd98Vs0TWU/Y89J89e5YA0MGDBy3W63Q60mq1Nv0Mo9FIYWFh9PLLL1vdnpKSYnX8YD5VtlRZWUkeHh4EgLZt2yas37lzJwEgPz8/Hm9ZZJI5Vfb19YVSqbQ6kVdgYKBNP6N///4YP368xVQmv8ez9dkmJCQEL730EgBAp9OhsbERAHDXXXchKCgIv/76K7788ksxS2Q9YNfgqlQqTJw40WIiL7PZjLy8PJsn8jKZTDh27FiXD37zbH22S0pKQlhYGKqrq/Haa68BuPwdeM6cOQD4mq6s2Pvw/9FHH5FarabNmzdTSUkJzZs3j7y8vKimpoaIiJ544glatmyZ0D41NZV2795N5eXl9P3339MjjzxC7u7udPz4cZvej3uVu/fFF18QAOrfvz+dOHGCiIhOnjxJAEihUFBlZaXIFbouyZwqA8DDDz+MNWvWYMWKFRg3bhyKi4uxa9cuocOqsrLS4kb4ixcvYu7cubjuuutw1113Qa/X4+DBg7j++uvtXapLuPvuu3HXXXfh0qVLWLJkCYgII0aMwJQpU0BEyM7OFrtEZgu7/xlxMD7iXtl//vMfUqlUBIBycnKIiGjbtm0EgEJDQ6mtrU3kCl2TpI64THpGjhyJpKQkAJfHYv7tt9/wwAMPwMvLC5WVlZ0mF2fSw8F1US+++CKuvvpqVFRUYM2aNRgwYAAef/xxANxJJQc8PKsL++ijjzB79my4u7vjxIkTqK+vx7hx49C/f3/88ssv8PX1FbtEl8LDszKbPPzww4iOjkZrayuSkpIQERGByMhIXLp0CVu3bhW7PNYNDq4LUygUWLduHZRKJbZv3468vDweHUMmOLgubsyYMcIMf4sXL8aDDz6IAQMGoKSkBEVFRSJXx7rCwWVITU2Fr68vSktLsXXrVjz00EMAuJNKyji4DN7e3khLSwMApKSk4P777wdwufOKn7aSJg4uAwA8/fTTuPHGG9HY2IgdO3Zg1KhRaGlpwccffyx2acwKDi4DYDky5JYtW4TBD/g5XWni4DJBVFQUnnrqKQBAQUEBlEolDh06hGPHjolcGeuIg8sspKWlwdPTE0ePHkVERAQAPupKEQeXWQgICEBqaioACIMXbN26Fa2trWKWxTrg4LJOFi5ciBtuuAF6vR4DBw5EXV0dcnJyxC6L/Q4Hl3XSv39/oaOqpaUFAF/TlRoOLrMqJiYGs2bNEm57zMvLw88//yxyVawdB5d1qf1xv3Y8OoZ0cHBZl0JDQ4WRIYHLvcttbW0iVsTacXBZt5KSkjBs2DAAQHV1NXbv3i1yRQyQ4Gx9APDpp59i9OjRcHd3x5gxY/DPf/7TEWUyK9zd3fHmm28Kr9euXSteMez/2Xn8K/roo49IpVLRpk2b6Pjx4zR37lzy8vKi2tpaq+2/+eYbUiqVlJ6eTiUlJfTyyy9T//796dixYza9Hw8W1/fMZjPdeuutwiwRv/zyi9glOaWefHYlN1vfQw89RDNmzLBYFxUVRfPnz7fp/Ti49lFWViYE9/rrrxe7HKckmVEeezNbX2FhoUV7AIiLi+uyPU/6ZV9msxkFBQV45513oFQqAQAlJSU4dOiQyJW5tn72/OHdzdbX1bSONTU1PZrdLy0tTbhFj/WNtrY2HDhwANu3b8eOHTssBqxvN3XqVBw5cgSjRo0SoUIm+15lnvSrbxiNRuzatQtz585FUFAQpk2bhqysLFRXV0Oj0eDxxx9HTk4OMjIyAFy+o+rWW29FWVmZyJW7JrsecXszW19gYGCP2qvVaqjV6r4p2MW0trYiNzcXn332Gb744gvU19cL2wYPHoyZM2fiwQcfxLRp06BSqQAARIRdu3YhNzcXv/76K2JiYpCfn89HXkez9xdurVZLixYtEl6bTCa6+uqru+2cuvvuuy3WTZo0iTun+khTUxN9+umn9PDDD9OgQYMs5hQODAykBQsW0N69e+nSpUtd/ozTp0/TgAEDhP2CgoKECcRY70mqV7mns/V988031K9fP1qzZg2VlpZSSkoKXw76g+rr62nbtm10//33WwQOAF1zzTW0ZMkSOnDgQI/mDEpPTycApFQqhdBzeP8YSQWXiGjdunUUGhpKKpWKtFotFRUVCduio6MpPj7eov0nn3xC1157LalUKrrhhhvoq6++svm9OLiXXbhwgTZt2kQzZswQJvhqX4YPH046nY6KiorIZDL16ucbjUYaM2YMASBvb28hvKWlpX38m7gOyQXXkVw5uDU1NbRhwwa6/fbbhSNh+zJ69Gh66aWX6IcffiCz2dwn73fw4EHh54eFhXF4/yAOrgsF98yZM/TWW29RdHQ0ubm5WYR17NixtHLlSpsnBe+NefPmEQAaOXKkcATm8PYOB9fJg1tRUUFr1qyhm266ySKoACgyMpJef/11OnnypENqqaurIz8/PwJAL774Io0dO5YAUEBAAIe3hzi4ThjcsrIyWrVqFU2YMMEiqAqFgiZPnkwZGRl0+vRpUWrbunUrASB3d3f67rvvKCIigsPbCxxcJwiu2WymY8eOUUpKCoWHh1uE1c3NjWJiYujtt9+ms2fPil0qmc1mmjZtGgGg6dOn07lz5yzCW1JSInaJssDBlWlwzWYzHT58mJYvX07XXnutRVj79etHcXFx9I9//IPOnTsndqmdlJWVCb3Xn3zyCZ0/f57D20McXBkF12Qy0cGDBykpKYmGDh1qEVa1Wk333nsvbdmyherq6sQu9YpSUlKEGzLq6+s7hdeenWTOgIMrUnANBgNlZmbSokWLKDMzkwwGg9V2bW1ttH//flq8eDFdffXVFmH18PCgP/3pT/Thhx+SXq938G/wx/z22280cuRIAiDcLcfhtR0HV4Tg6nS6TtdOlUol6XQ6Irp8w0Jubi7Nnz+f/P39LdpdddVV9Oijj9L27dupubnZoXX3tT179gidZt999x0RXQ7vuHHjCAD5+/tzeLvAwXVwcHU6XafLMr9fwsPDycfHx2Kdt7c3zZkzh7744gtqbW11WK2O8NhjjxEAmjBhgnDPM4f3yji4DgyuwWDodKTtavHz86N58+ZRbm4uGY1Gh9QnhpqaGvLy8iIAtHbtWmH9+fPnafz48RzeLnBwHRjczMxMm0K7cOHCHt3EL3cbNmwgADRo0CA6c+aMsP7ChQsW4f3pp59ErFJaJDN0jSsoLy+3qZ1CoRCGfnEFc+fOxU033YSmpiYsWbJEWO/j44O9e/di/PjxOHfuHKZOnYrjx4+LWKk8cXD/oLCwsD5t5yzc3Nzw97//HUqlEtu3b8dXX30lbOsY3piYGA5vTzngDMChpPgdV6lUdnlpyNn9+c9/JgA0dOjQTj3mvz9t9vPzc/nTZj5VdiCVSoXExMRu2yQmJgpDv7ialJQUhISE4PTp01i5cqXFtvYj74QJE4RhcPjIayMH/CFxKKlex3VlO3fuFG7btDaSyYULF4SHJ/z8/Gwe7cTZ9OSzqyD63zyKTkKv10Oj0aChoQGenp4OfW+j0YisrCyUl5cjLCwMCQkJLnuk7ej+++9HTk4OJk+ejAMHDsDNzfJkr66uDrfffjuOHDkCPz8/7Nu3D+Hh4SJVK44efXbt/mfEweR2r7KrqKyspIEDBxIA2rhxo9U2dXV1Ln3klcx33Lq6Ojz22GPw9PSEl5cXnnnmGTQ1NXW7z5QpU6BQKCyW5557zp5lMgcICQkRvuMmJyfj119/7dTG29sbe/fuxcSJE4XvvD/99JOjS5UHe/4FmT59OkVERFBRURH9+9//phEjRtDs2bO73Sc6Oprmzp1L1dXVwtKToycfcaXr0qVLwgMHTz75ZJft6urqaOLEiQSAfH196ccff3RgleKRxJ1TJSUlBEC40ZyI6OuvvyaFQtHtw9/R0dG0ZMmSXr8vB1faioqKSKFQEADat29fl+1cMbySOFUuLCyEl5cXIiMjhXWxsbFwc3O74oRR77//Pnx9fREeHo7ly5ejpaWly7Y86Ze8REVFCV99FixYAIPBYLWdt7c39uzZg8jISJw/fx5Tp07FsWPHHFmqpNktuDU1NfD397dY169fP/j4+HQ5gRcAPProo9i2bRvy8/OxfPlybN26FY8//niX7dPS0qDRaIQlJCSkz34HZh9//etfERAQgLKyMqxevbrLdt7e3sjNzbUI748//ujASiWsp4fzv/zlL1e8ob60tJRWrVpF1157baf9/fz8KCsry+b3y8vLIwB06tQpq9tbW1upoaFBWKqqqvhUWQY++OADYZSPK41IefHiRYqMjBROm48ePeqgKh3LrqfKSUlJKC0t7XYZPnw4AgMDce7cOYt929raUFdX1+UEXtZERUUBAE6dOmV1u1qthqenp8XCpO+RRx5BbGwsDAYDEhISQN3cTuDl5dXptNnlj7z2+uvR3jl1+PBhYd3u3buv2DnVUUFBAQGw+a8sd07Jx8mTJ0mtVhMA+vDDD6/Y/uLFi3TjjTcSABo8eLDTHXkl0atMdPly0Pjx4+nQoUNUUFBAI0eOtLgcdObMGRo1ahQdOnSIiIhOnTpFK1eupMOHD1NFRQXt3LmThg8fTrfddpvN78nBlZeVK1cK41FdvHjxiu07hre4uNj+RTqIZIJ74cIFmj17Ng0aNIg8PT3pqaeeosbGRmF7RUUFAaD8/Hwiunx3zW233UY+Pj6kVqtpxIgRpNPp+DquE2ttbaVRo0YRAEpISLBpH2cNr2SCKwYOrvzs27dPGGCu/ezrSi5evEhardapwiuJ67iM2SomJgZPPPEEiAjz589HW1vbFffx8vLC7t27odVqceHCBUybNg1Hjx6F0WjE2rVrsXjxYqxduxZGo9EBv4EI7P93xLH4iCtPtbW1wjy7GRkZNu9XX18vHHnd3d07zVgop0cr+YjLZMff3x9vvPEGAOCVV15BVVWVTftpNBrk5uYiMDAQra2tMJvNFttNJhNWr16N5OTkPq9ZTBxcJhnPPPMMJk+ejObmZjz//PM27zdgwIBO9wx0lJGR4VSnzRxcJhlubm5455130K9fP+Tk5ODzzz+3ab+srKxOR9qOTCYTsrKy+qJMSeDgMkkZM2aMMIbX4sWL0dzcfMV9bB0i19Z2csDBZZKzYsUKDBkyBJWVlUhNTb1ie1ccIpfHnGKS9OWXX+Kee+6BUqnEkSNHMHbs2C7bGo1GeHh4wGQyddlGqVSipaVF0mOA9eSzy0dcJkl33303HnjgAZhMJsyfPx+tra1dXp91ySFy7X5xysH4Oq7zqKqqokGDBgl3VeEK12flPkQuD8/Kp8pOY+rUqcjPz+9yu06nQ3p6uvBazkPk9uSzy8FlkuUs311txd9xmVPIysrqNrSA812ftRUHl0mWK16ftRUHl0mWK16ftRV/x2WSxd9xu8ZHXCZZLnl91kb9xC6Ase60X+rJyMiwOPIqlUokJiZaXApyJXY74q5atQo333wzPDw84OXlZdM+RIQVK1YgKCgIAwYMQGxsLE6ePGmvEplMpKeno6WlBZmZmVi0aBEyMzPR0tLisqEF7HjENRqNmDVrFiZNmoR3333Xpn3S09Px1ltvYcuWLRg2bBheeeUVxMXFoaSkBO7u7vYqlcmASqXC0qVLxS5DOux5CxcRUXZ2Nmk0miu2M5vNFBgYSKtXrxbW1dfXk1qttmnM3XZ8yyOTK1kOXVNRUYGamhrExsYK6zQaDaKiolBYWNjlfjzpF3NFkglu+0RgAQEBFusDAgK6nSSMJ/1irqhHwV22bFmn2eI7LidOnLBXrVYtX74cDQ0NwmLrIGOMyVmPOqeSkpIwZ86cbtsMHz68V4W0TwRWW1uLoKAgYX1tbS3GjRvX5X5qtRpqtbpX78mYXPUouH5+fvDz87NLIcOGDUNgYCDy8vKEoOr1ehw6dAgLFiywy3syJld2+45bWVmJ4uJiVFZWwmQyobi4GMXFxWhqahLajB49Gjt27AAAKBQKLF26FK+99ho+//xzHDt2DE8++SSCg4Mxc+ZMe5XJmCzZ7TruihUrsGXLFuH1+PHjAQD5+fmYMmUKAKCsrAwNDQ1Cm+TkZDQ3N2PevHmor6/HLbfcgl27dvE1XMY64IcMGJMIfsiAMSfHwWVMhji4jMkQB5cxGeLgMiZDHFzGZIiDy5gMcXAZkyEOLmMyxMFlTIY4uIzJEAeXMRni4DImQxxcxmSIg8uYDHFwGZMhDi5jMsTBZUyGJDXp15w5czqN0zx9+nR7lciYbElq0i8AmD59OrKzs4XXPGYyY53ZLbipqakAgM2bN/doP7VaLQyOzhizTnITW+/fvx/+/v7w9vbG1KlT8dprr2Hw4MFdtjcYDDAYDMLr9uFeefIvJjftn1lbBl6VVHCnT5+OBx54AMOGDUN5eTlefPFF3HnnnSgsLIRSqbS6T1pamnB0/z2e/IvJVWNjIzQaTbdtejSu8rJly/DGG29026a0tBSjR48WXm/evBlLly5FfX29rW8j+PnnnxEWFoa9e/di2rRpVtt0POKazWbU1dVh8ODBUCgUPX7P3tLr9QgJCUFVVZVTj+fMv6f9EBEaGxsRHBwMN7fu+40lM+lXVz/L19cXp06d6jK41ib9srUX2x48PT2d+gPdjn9P+7jSkbadZCb9subMmTO4cOGCxex9jDEJTfrV1NQEnU6HoqIinD59Gnl5ebjvvvswYsQIxMXF2atMxuSJ7CQ+Pp4AdFry8/OFNgAoOzubiIhaWlrojjvuID8/P+rfvz8NGTKE5s6dSzU1NfYqsU+1trZSSkoKtba2il2KXfHvKQ1ON+kXY66A71VmTIY4uIzJEAeXMRni4DImQxxcO+jNI41ysH79egwdOhTu7u6IiorCt99+K3ZJfe7AgQO45557EBwcDIVCgZycHLFLsoqDawftjzQuWLBA7FL6zMcff4zExESkpKTgyJEjiIiIQFxcHM6dOyd2aX2qubkZERERWL9+vdildE/s61HOLDs7mzQajdhl9AmtVksLFy4UXptMJgoODqa0tDQRq7IvALRjxw6xy7CKj7jsioxGI77//nvExsYK69zc3BAbG4vCwkIRK3NdHFx2RefPn4fJZEJAQIDF+oCAANTU1IhUlWvj4Npo2bJlncbD6ricOHFC7DKZi5DUg/RS5uhHGqXE19cXSqUStbW1Futra2t5mCGRcHBt5OhHGqVEpVJh4sSJyMvLw8yZMwFcHrAgLy8PixYtErc4F8XBtYPKykrU1dVZPNIIACNGjMCgQYPELa6XEhMTER8fj8jISGi1WqxduxbNzc146qmnxC6tTzU1NeHUqVPC64qKChQXF8PHxwehoaEiVtaB2N3azsiWRxrlaN26dRQaGkoqlYq0Wi0VFRWJXVKfy8/Pt/p/Fx8fL3ZpFvixPsZkiHuVGZMhDi5jMsTBZUyGOLiMyRAHlzEZ4uAyJkMcXMZkiIPLmAxxcBmTIQ4uYzLEwWVMhji4jMnQ/wHPdQPk9hsTpwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 250x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "utils.plot_features_in_2d(\n",
        "    W_normed.unsqueeze(0), # shape [instances=1 d_hidden=2 features=5]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoV1OW2D5DSz"
      },
      "source": [
        "Compare this plot to the `imshow` plot above, and make sure you understand what's going on here (and how the two plots relate to each other). A lot of the subsequent exercises run with this idea of a geometric interpretation of the model's features and bottleneck dimensions.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how these plots work.</summary>\n",
        "\n",
        "As mentioned, you can view $W$ as being a set of five 2D vectors, one for each of our five features. The heatmap shows us the cosine similarities between each pair of these vectors, and the second plot shows us these five vectors in 2D space.\n",
        "\n",
        "In the example above, we can see two pairs of vectors (the 1st & 2nd, and the 0th & 4th) have very high cosine similarity. This is reflected in the 2D plot, where these features are very close to each other (the 0th feature is the darkest color, the 4th feature is the lightest).\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi5wznZsWNfL"
      },
      "source": [
        "### Defining our model\n",
        "\n",
        "Below is some code for your model (with most methods not filled out yet). It should be familiar to you if you've already built simple neural networks earlier in this course.\n",
        "\n",
        "Some notes on the initialization method, which is filled out for you:\n",
        "\n",
        "#### Weights & instances\n",
        "\n",
        "The `Config` class has an `n_inst` class. This is so we can optimize multiple models at once in a single training loop (this'll be useful later on). You should treat this as basically like a batch dimension for your weights: each of your weights/biases will actually be `n_inst` separate weights/biases stacked along the zeroth dimension, and each of these will be trained independently, on different data, in parallel (using the same optimizer).\n",
        "\n",
        "We initialize weights `W` and `b_final`, which correspond to $W$ and $b$ in the Anthropic paper.\n",
        "\n",
        "#### Feature probability and sparsity\n",
        "\n",
        "The `feature_probability` and `importance` arguments correspond to sparsity and importance of features.\n",
        "\n",
        "We have the relation  `feature_probability = 1 - sparsity`. We'll usually refer to the feature probability rather than the sparsity, since this is easier. We'll often be dealing with very small values $p = 1 - S \\approx 0$. The feature probability is used to generate our training data; the importance is used in our loss function (see later for both of these). The default is `feature_probability = None`, which means $p = 1$ (no sparsity).\n",
        "\n",
        "The `importance` argument is used when calculating loss (see later exercise). The default is `importance = None` which results in uniform importance.\n",
        "\n",
        "In the `__init__` method, we have code to broadcast `feature_probability` and `importance`, so that by the end they both always have shape `(n_inst, n_features)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-SyxUz05DSz"
      },
      "source": [
        "### Exercise - implement `forward`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-20 minutes on this exercise.\n",
        "```\n",
        "\n",
        "For now, you just need to fill in the `forward` method. As the exercises go on, you'll fill in some more of these functions, but for now you can ignore the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DRQ9j4ftyHXf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests in `test_model` passed!\n"
          ]
        }
      ],
      "source": [
        "def linear_lr(step, steps):\n",
        "    return (1 - (step / steps))\n",
        "\n",
        "def constant_lr(*_):\n",
        "    return 1.0\n",
        "\n",
        "def cosine_decay_lr(step, steps):\n",
        "    return np.cos(0.5 * np.pi * step / (steps - 1))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # We optimize n_inst models in a single training loop to let us sweep over sparsity or importance\n",
        "    # curves efficiently. You should treat the number of instances `n_inst` like a batch dimension,\n",
        "    # but one which is built into our training setup. Ignore the latter 3 arguments for now, they'll\n",
        "    # return in later exercises.\n",
        "    n_inst: int\n",
        "    n_features: int = 5\n",
        "    d_hidden: int = 2\n",
        "    n_correlated_pairs: int = 0\n",
        "    n_anticorrelated_pairs: int = 0\n",
        "    feat_mag_distn: Literal[\"unif\", \"jump\"] = \"unif\"\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    W: Float[Tensor, \"inst d_hidden feats\"]\n",
        "    b_final: Float[Tensor, \"inst feats\"]\n",
        "\n",
        "    # Our linear map (for a single instance) is x -> ReLU(W.T @ W @ x + b_final)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        cfg: Config,\n",
        "        feature_probability: float | Tensor = 0.01,\n",
        "        importance: float | Tensor = 1.0,\n",
        "        device=device,\n",
        "    ):\n",
        "        super(Model, self).__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        if isinstance(feature_probability, float):\n",
        "            feature_probability = t.tensor(feature_probability)\n",
        "        self.feature_probability = feature_probability.to(device).broadcast_to(\n",
        "            (cfg.n_inst, cfg.n_features)\n",
        "        )\n",
        "        if isinstance(importance, float):\n",
        "            importance = t.tensor(importance)\n",
        "        self.importance = importance.to(device).broadcast_to((cfg.n_inst, cfg.n_features))\n",
        "\n",
        "        self.W = nn.Parameter(\n",
        "            nn.init.xavier_normal_(t.empty((cfg.n_inst, cfg.d_hidden, cfg.n_features)))\n",
        "        )\n",
        "        self.b_final = nn.Parameter(t.zeros((cfg.n_inst, cfg.n_features)))\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        features: Float[Tensor, \"... inst feats\"],\n",
        "    ) -> Float[Tensor, \"... inst feats\"]:\n",
        "        # YOUR CODE HERE\n",
        "        A = einops.einsum(self.W, self.W, \"inst d_hidden feats_in, inst d_hidden feats_out -> inst feats_in feats_out\")\n",
        "        return t.relu(einops.einsum(A, features, \"inst feats_in feats_out, ... inst feats_in -> ... inst feats_out\") + self.b_final)\n",
        "\n",
        "\n",
        "    def generate_batch(self, batch_size) -> Float[Tensor, \"batch inst feats\"]:\n",
        "        \"\"\"\n",
        "        Generates a batch of data.\n",
        "        \"\"\"\n",
        "        # You'll fill this in later\n",
        "        repeated_probs = einops.repeat(self.feature_probability, \"... -> b ...\", b = batch_size)\n",
        "        return t.bernoulli(repeated_probs) * t.rand(repeated_probs.shape)\n",
        "\n",
        "\n",
        "    def calculate_loss(\n",
        "        self,\n",
        "        out: Float[Tensor, \"batch inst feats\"],\n",
        "        batch: Float[Tensor, \"batch inst feats\"],\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Calculates the loss for a given batch (as a scalar tensor), using this loss described in the\n",
        "        Toy Models of Superposition paper:\n",
        "\n",
        "            https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating-setup-loss\n",
        "\n",
        "        Note, `self.importance` is guaranteed to broadcast with the shape of `out` and `batch`.\n",
        "        \"\"\"\n",
        "        # You'll fill this in later\n",
        "        return (self.out - self.batch)**2 * self.importance\n",
        "\n",
        "\n",
        "    def optimize(\n",
        "        self,\n",
        "        batch_size: int = 1024,\n",
        "        steps: int = 10_000,\n",
        "        log_freq: int = 50,\n",
        "        lr: float = 1e-3,\n",
        "        lr_scale: Callable[[int, int], float] = constant_lr,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Optimizes the model using the given hyperparameters.\n",
        "        \"\"\"\n",
        "        optimizer = t.optim.Adam(list(self.parameters()), lr=lr)\n",
        "\n",
        "        progress_bar = tqdm(range(steps))\n",
        "\n",
        "        for step in progress_bar:\n",
        "            # Update learning rate\n",
        "            step_lr = lr * lr_scale(step, steps)\n",
        "            for group in optimizer.param_groups:\n",
        "                group[\"lr\"] = step_lr\n",
        "\n",
        "            # Optimize\n",
        "            optimizer.zero_grad()\n",
        "            batch = self.generate_batch(batch_size)\n",
        "            out = self(batch)\n",
        "            loss = self.calculate_loss(out, batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Display progress bar\n",
        "            if step % log_freq == 0 or (step + 1 == steps):\n",
        "                progress_bar.set_postfix(loss=loss.item() / self.cfg.n_inst, lr=step_lr)\n",
        "\n",
        "\n",
        "tests.test_model(Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZElPqnT5DS0"
      },
      "source": [
        "### Exercise - implement `generate_batch`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Next, you should implement the function `generate_batch` above. This should return a tensor of shape `(n_batch, instances, features)`, where:\n",
        "\n",
        "* The `instances` and `features` values are taken from the model config,\n",
        "* Each feature is present with probability `self.feature_probability`,\n",
        "* For each present feature, its **magnitude** is sampled from a uniform distribution between 0 and 1.\n",
        "\n",
        "Make sure you understand this function well (we recommend looking at the solutions even after you pass the tests), because we'll be making more complicated versions of this function in the section on correlations.\n",
        "\n",
        "Remember, you can assume `model.feature_probability` has shape `(n_inst, n_features)`.\n",
        "\n",
        "When you've implemented this function, run the code below to test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ERULbPlfCkP5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests in `test_generate_batch` passed!\n"
          ]
        }
      ],
      "source": [
        "tests.test_generate_batch(Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtjKlA3D5DS0"
      },
      "source": [
        "## Training our model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmYChnxI5DS0"
      },
      "source": [
        "The details of training aren't very conceptually important, so we've given you most of the code to train the model below. We use **learning rate schedulers** to control the learning rate as the model trains - you'll use this later on during the RL chapter.\n",
        "\n",
        "### Exercise - implement `calculate_loss`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "You should fill in the `calculate_loss` function below. The loss function **for a single instance** is given by:\n",
        "\n",
        "$$\n",
        "L=\\frac{1}{BF}\\sum_x \\sum_i I_i\\left(x_i-x_i^{\\prime}\\right)^2\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $B$ is the batch size,\n",
        "* $F$ is the number of features,\n",
        "* $x_i$ are the inputs and $x_i'$ are the model's outputs,\n",
        "* $I_i$ is the importance of feature $i$,\n",
        "* $\\sum_i$ is a sum over features,\n",
        "* $\\sum_x$ is a sum over the elements in the batch.\n",
        "\n",
        "For the general case, we sum this formula over all instances.\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do you think we take the mean over the feature and batch dimensions, but we sum over the instances dimension?</summary>\n",
        "\n",
        "We take the mean over batch size because this is standard for loss functions (and means we don't have to use a different learning rate for different batch sizes).\n",
        "\n",
        "We take the mean over the feature dimension because that's [normal for MSE loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html).\n",
        "\n",
        "We sum over the instances dimension because we want to train each instance independently, and at the same rate as we would train a single instance.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67xWrkkfCqF4"
      },
      "outputs": [],
      "source": [
        "tests.test_calculate_loss(Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXnpzusQ5DS0"
      },
      "source": [
        "Now, we'll reproduce a version of the figure from the introduction, although with a slightly different version of the code.\n",
        "\n",
        "A few notes:\n",
        "\n",
        "* The `importance` argument is the same for all instances. It takes values between 1 and ~0.66 for each feature (so for every instance, there will be some features which are more important than others).\n",
        "* The `feature_probability` is the same for all features, but it varies across instances. In other words, we're runnning several different experiments at once, and we can compare the effect of having larger feature sparsity in these experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36IE7Q2i5DS0"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=8, n_features=5, d_hidden=2)\n",
        "\n",
        "# importance varies within features for each instance\n",
        "importance = (0.9 ** t.arange(cfg.n_features))\n",
        "\n",
        "# sparsity is the same for all features in a given instance, but varies over instances\n",
        "feature_probability = (50 ** -t.linspace(0, 1, cfg.n_inst))\n",
        "\n",
        "line(importance, width=600, height=400, title=\"Importance of each feature (same over all instances)\", labels={\"y\": \"Feature importance\", \"x\": \"Feature\"})\n",
        "line(feature_probability, width=600, height=400, title=\"Feature probability (varied over instances)\", labels={\"y\": \"Probability\", \"x\": \"Instance\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN_lZC_95DS1"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIfWALMz2cKG"
      },
      "outputs": [],
      "source": [
        "utils.plot_features_in_2d(\n",
        "    model.W,\n",
        "    colors=model.importance,\n",
        "    title=f\"Superposition: {cfg.n_features} features represented in 2D space\",\n",
        "    subplot_titles=[f\"1 - S = {i:.3f}\" for i in feature_probability.squeeze()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okuSmfVTvw-l"
      },
      "source": [
        "<details>\n",
        "<summary>Click this dropdown to see what you should be getting from this visualisation.</summary>\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/sp1.png\" width=\"1400\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoeqf0X_5DS1"
      },
      "source": [
        "### Exercise - interpret these diagrams\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 10-20 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Remember that for all these diagrams, the darker colors have lower importance and the lighter colors have higher importance. Also, the sparsity of all features is increasing as we move from left to right (at the far left there is no sparsity, at the far right feature probability is 5% for all features, i.e. sparsity of 95%).\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "For low sparsity, think about what the model would learn to do if all 5 features were present all the time. What's the best our model could do in this case, and how does that relate to the **importance** values?\n",
        "\n",
        "For high sparsity, think about what the model would learn to do if there was always exactly one feature present. Does this make interference between features less of a problem?\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer (intuitive)</summary>\n",
        "\n",
        "When there is no sparsity, the model can never represent more than 2 features faithfully, so it makes sense for it to only represent the two most important features. It stores them orthogonally in 2D space, and sets the other 3 features to zero. This way, it can reconstruct these two features perfectly, and ignores all the rest.\n",
        "\n",
        "When there is high sparsity, we get a pentagon structure. Most of the time at most one of these five features will be active, which helps avoid **interference** between features. When we try to recover our initial features by projecting our point in 2D space onto these five directions, most of the time when feature $i$ is present, we can be confident that our projection onto the $i$-th feature direction only captures this feature, rather than being affected by the presence of other features. We omit the mathematical details here.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/download (7).png\" width=\"900\">\n",
        "\n",
        "The key idea here is that two forces are competing in our model: **feature benefit** (representing more thing is good!), and **interference** (representing things non-orthogonally is bad). The higher the sparsity, the more we can reduce the negative impact of interference, and so the trade-off skews towards \"represent more features, non-orthogonally\".\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHrZbz2Ovw-l"
      },
      "source": [
        "We can also generate a batch and visualise its embedding. Most interestingly, you should see that in the plots with high sparsity (to the right), we very rarely have interference between the five features, because most often $\\leq 1$ of those features is present, and the model can recover it by projecting along the corresponding feature dimension without losing any information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDe0QWPRvw-l"
      },
      "outputs": [],
      "source": [
        "with t.inference_mode():\n",
        "    batch = model.generate_batch(200)\n",
        "    hidden = einops.einsum(batch, model.W, \"batch_size instances features, instances hidden features -> instances hidden batch_size\")\n",
        "\n",
        "utils.plot_features_in_2d(hidden, title = \"Hidden state representation of a random batch of data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUzv08Tpvw-l"
      },
      "source": [
        "<details>\n",
        "<summary>Click this dropdown to see what you should be getting from this visualisation.</summary>\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/hs1.png\" width=\"1400\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1RzkWqn5DS1"
      },
      "source": [
        "## Visualizing features across varying sparsity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPHR2UBZ5DS1"
      },
      "source": [
        "Now that we've got our pentagon plots and started to get geometric intuition for what's going on, let's scale things up! We're now operating in dimensions too large to visualise, but hopefully our intuitions will carry over.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWGU8wAn5DS1"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=10, n_features=100, d_hidden=20)\n",
        "\n",
        "importance = 100 ** -t.linspace(0, 1, cfg.n_features)\n",
        "feature_probability = 20 ** -t.linspace(0, 1, cfg.n_inst)\n",
        "\n",
        "line(importance, width=600, height=400, title=\"Importance of each feature (same over all instances)\", labels={\"y\": \"Feature importance\", \"x\": \"Feature\"})\n",
        "line(feature_probability, width=600, height=400, title=\"Feature probability (varied over instances)\", labels={\"y\": \"Probability\", \"x\": \"Instance\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1O9Jb7nvw-o"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9uXMREt5DS1"
      },
      "source": [
        "Because we can't plot features in 2D anymore, we're going to use a different kind of visualisation:\n",
        "\n",
        "* The **bottom row plots** shows a bar graph of all the features and their corresponding embedding norms $||W_i||$.\n",
        "    * As we increase sparsity, the model is able to represent more features (i.e. we have more features with embedding norms close to 1).\n",
        "    * We also color the bars according to whether they're orthogonal to other features (purple) or not (yellow). So we can see that for low sparsity most features are represented orthogonally (like our left-most plots above) but as we increase sparsity we transition to all features being represented non-orthogonally (like our right-most pentagon plots above).\n",
        "* The **top row plots** show us the dot products between all pairs of feature vectors (kinda like the heatmaps we plotted at the start of this section).\n",
        "    * This is another way of visualising the increasing interference between features as we increase sparsity.\n",
        "    * Note that all these right hand plots represent **matrices with rank at most `d_hidden=20`**. The first few are approximately submatrices of the identity (because we perfectly reconstruct 20 features and delete the rest), but the later plots start to display inference as we plot more than 20 values (the diagonals of these matrices have more than 20 non-zero elements).\n",
        "\n",
        "See the section [Basic Results](https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating-basic-results) for more of an explanation of this graph and what you should interpret from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVGrWm790Z_z"
      },
      "outputs": [],
      "source": [
        "utils.plot_features_in_Nd(\n",
        "    model.W,\n",
        "    height=800,\n",
        "    width=1600,\n",
        "    title=\"ReLU output model: n_features = 80, d_hidden = 20, I<sub>i</sub> = 0.9<sup>i</sup>\",\n",
        "    subplot_titles=[f\"Feature prob = {i:.3f}\" for i in feature_probability],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq_Vqe_u2cKL"
      },
      "source": [
        "## Bonus - varying feature probability across features\n",
        "\n",
        "In this section, we've only discussed varying feature probability across instances, and so most of the learned solutions have had uniformity (e.g. a uniform pentagon, or a uniform digon with one feature collapsed). But there's also a large set of non-uniform patterns which can be learned by our models. See the [corresponding section](https://transformer-circuits.pub/2022/toy_model/index.html#geometry-non-uniform) of the Anthropic paper, where they discuss in more detail what happens when a feature's importance is perturbed. Can you reproduce this result? Can you think of a setup which would result in a learned solution where all 5 features are represented, but two features are represented with very high cosine similarity? (You might want to return to this question at the end of the next section!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cBVpwSy2cKL"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - replicate Anthropic's peturbing results (optional)\n",
        "\n",
        "# See the solutions Colab or Streamlit page for replication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUtONps5DS4"
      },
      "source": [
        "# 2️⃣ TMS: Correlated / Anticorrelated Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efN1F9no5DS5"
      },
      "source": [
        "## Superposition with correlation\n",
        "\n",
        "One major thing we haven't considered in our experiments is **correlation**. We could guess that superposition is even more common when features are **anticorrelated** (for a similar reason as why it's more common when features are sparse). Most real-world features are anticorrelated (e.g. the feature \"this is a sorted Python list\" and \"this is some text in an edgy teen vampire romance novel\" are probably anticorrelated - that is, unless you've been reading some pretty weird fanfics).\n",
        "\n",
        "In this section, you'll define a new data-generating function for correlated features, and run the same experiments as in the first section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWXvuxOS5DS5"
      },
      "source": [
        "### Exercise - implement `generate_correlated_batch`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵🔵⚪⚪⚪\n",
        "\n",
        "You should spend up to 20-40 minutes on this exercise.\n",
        "\n",
        "The exercise itself is not conceptually important, and it is a bit fiddly / delicate, so you should definitely look at the\n",
        "solutions if you get stuck. Understanding the results and why they occur is more important than the implementation!\n",
        "```\n",
        "\n",
        "You should now fill in the three methods `generate_correlated_features`, `generate_anticorrelated_features` and `generate_uncorrelated_features` in the `Model` class, which are created to generate correlated / anticorrelated data. We've given you a new `generate_batch` function which returns the aggregation from all of these methods.\n",
        "\n",
        "Note, in the correlated & anticorrelated cases you can assume that the feature probability is the same for all features in each instance. We start these functions by asserting this for you, and creating a vector `p` which contains this feature probability for each instance (which is what you should use instead of `model.feature_probability`). The same is also true for the uncorrelated case, when the number of uncorrelated features we're generating is less than `cfg.n_features` (since if not, it's fine to use the full `self.feature_probability` tensor).\n",
        "\n",
        "You'll also need to be careful with your probabilities in the anticorrelated case. For example, if you do the following for your pair of features 1 & 2:\n",
        "\n",
        "```python\n",
        "feat1_is_present = t.rand() < p\n",
        "feat2_is_present = t.rand() < p & ~feat1_is_present\n",
        "```\n",
        "\n",
        "then your `feat2` probability will actually be `p * (1 - p)` rather than the intended `p`. You want to try and make both features have probability `p`, while _also_ ensuring that they are never both active at the same time! The hints provide some guidance on how you can implement this (it's a bit fiddly and not very conceptually important!).\n",
        "\n",
        "For more details, you can read the [experimental details in Anthropic's paper](https://transformer-circuits.pub/2022/toy_model/index.html#geometry-correlated-setup), where they describe how they setup correlated and anticorrelated sets.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how to implement the correlated features function.</summary>\n",
        "\n",
        "Try first creating a boolean mask of shape `(batch_size, n_inst, n_correlated_pairs)` representing whether the pair is present, then repeating that mask across feature pairs with `einops.repeat`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how to implement the anticorrelated features function.</summary>\n",
        "\n",
        "Here are 2 suggested methods:\n",
        "\n",
        "1. Create a boolean mask of shape `(batch_size, n_inst, n_anticorrelated_pairs)` with probability $2p$, which represents whether *either* feature is present - and where true, we choose the present feature uniform randomly from the pair. This works because both features will have probability $2p \\times 0.5 = p$.\n",
        "2. Create 2 boolean masks `M1, M2` both of shape `(batch_size, n_inst, n_anticorrelated_pairs)` with probability $p$ and $p / (1 - p)$ respectively. Set the first feature to be present where `M1` is true, and the second feature to be present where `~M1 && M2` is true. This works because the first feature will have probability $p$, and the second will have probability $\\frac{(1 - p)p}{(1 - p)} = p$.\n",
        "\n",
        "The solutions use a method like (2), but either is valid.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Gx1k8gCbJZ"
      },
      "outputs": [],
      "source": [
        "def generate_correlated_features(\n",
        "    self, batch_size: int, n_correlated_pairs: int\n",
        ") -> Float[Tensor, \"batch inst 2*n_correlated_pairs\"]:\n",
        "    \"\"\"\n",
        "    Generates a batch of correlated features. For each pair `batch[i, j, [2k, 2k+1]]`, one of\n",
        "    them is non-zero if and only if the other is non-zero.\n",
        "    \"\"\"\n",
        "    assert t.all((self.feature_probability == self.feature_probability[:, [0]]))\n",
        "    p = self.feature_probability[:, [0]]  # shape (n_inst, 1)\n",
        "\n",
        "    # YOUR CODE HERE!\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def generate_anticorrelated_features(\n",
        "    self, batch_size: int, n_anticorrelated_pairs: int\n",
        ") -> Float[Tensor, \"batch inst 2*n_anticorrelated_pairs\"]:\n",
        "    \"\"\"\n",
        "    Generates a batch of anti-correlated features. For each pair `batch[i, j, [2k, 2k+1]]`, each\n",
        "    of them can only be non-zero if the other one is zero.\n",
        "    \"\"\"\n",
        "    assert t.all((self.feature_probability == self.feature_probability[:, [0]]))\n",
        "    p = self.feature_probability[:, [0]]  # shape (n_inst, 1)\n",
        "\n",
        "    assert p.max().item() <= 0.5, \"For anticorrelated features, must have 2p < 1\"\n",
        "\n",
        "    # YOUR CODE HERE!\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def generate_uncorrelated_features(self, batch_size: int, n_uncorrelated: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Generates a batch of uncorrelated features.\n",
        "    \"\"\"\n",
        "    if n_uncorrelated == self.cfg.n_features:\n",
        "        p = self.feature_probability\n",
        "    else:\n",
        "        assert t.all((self.feature_probability == self.feature_probability[:, [0]]))\n",
        "        p = self.feature_probability[:, [0]]  # shape (n_inst, 1)\n",
        "\n",
        "    # YOUR CODE HERE!\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def generate_batch(self, batch_size) -> Float[Tensor, \"batch inst feats\"]:\n",
        "    \"\"\"\n",
        "    Generates a batch of data, with optional correlated & anticorrelated features.\n",
        "    \"\"\"\n",
        "    n_corr_pairs = self.cfg.n_correlated_pairs\n",
        "    n_anti_pairs = self.cfg.n_anticorrelated_pairs\n",
        "    n_uncorr = self.cfg.n_features - 2 * n_corr_pairs - 2 * n_anti_pairs\n",
        "\n",
        "    data = []\n",
        "    if n_corr_pairs > 0:\n",
        "        data.append(self.generate_correlated_features(batch_size, n_corr_pairs))\n",
        "    if n_anti_pairs > 0:\n",
        "        data.append(self.generate_anticorrelated_features(batch_size, n_anti_pairs))\n",
        "    if n_uncorr > 0:\n",
        "        data.append(self.generate_uncorrelated_features(batch_size, n_uncorr))\n",
        "    batch = t.cat(data, dim=-1)\n",
        "    return batch\n",
        "\n",
        "\n",
        "Model.generate_correlated_features = generate_correlated_features\n",
        "Model.generate_anticorrelated_features = generate_anticorrelated_features\n",
        "Model.generate_uncorrelated_features = generate_uncorrelated_features\n",
        "Model.generate_batch = generate_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e22Bzep5DS5"
      },
      "source": [
        "The code below tests your function, by generating a large number of batches and measuring them statistically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAzw5QzW5DS5"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=30, n_features=4, d_hidden=2, n_correlated_pairs=1, n_anticorrelated_pairs=1)\n",
        "\n",
        "feature_probability = 10 ** -t.linspace(0.5, 1, cfg.n_inst).to(device)\n",
        "\n",
        "model = Model(cfg=cfg, device=device, feature_probability=feature_probability[:, None])\n",
        "\n",
        "# Generate a batch of 4 features: first 2 are correlated, second 2 are anticorrelated\n",
        "batch = model.generate_batch(batch_size=100_000)\n",
        "corr0, corr1, anticorr0, anticorr1 = batch.unbind(dim=-1)\n",
        "\n",
        "assert ((corr0 != 0) == (corr1 != 0)).all(), \"Correlated features should be active together\"\n",
        "assert (\n",
        "    ((corr0 != 0).float().mean(0) - feature_probability).abs().mean() < 0.002\n",
        "), \"Each correlated feature should be active with probability `feature_probability`\"\n",
        "\n",
        "assert (\n",
        "    (anticorr0 != 0) & (anticorr1 != 0)\n",
        ").int().sum().item() == 0, \"Anticorrelated features should never be active together\"\n",
        "assert (\n",
        "    ((anticorr0 != 0).float().mean(0) - feature_probability).abs().mean() < 0.002\n",
        "), \"Each anticorrelated feature should be active with probability `feature_probability`\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPbBOuMs2cKL"
      },
      "source": [
        "We can also visualise these features, in the form of a bar chart. You should see the correlated features always co-occurring, and the anticorrelated features never co-occurring.\n",
        "\n",
        "<details>\n",
        "<summary>What you should see when you run the code below</summary>\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/bar-cooccur.png\" width=\"800\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ht50Dy5DS5"
      },
      "outputs": [],
      "source": [
        "# Generate a batch of 4 features: first 2 are correlated, second 2 are anticorrelated\n",
        "batch = model.generate_batch(batch_size=1)\n",
        "correlated_feature_batch, anticorrelated_feature_batch = batch.split(2, dim=-1)\n",
        "\n",
        "# Plot correlated features\n",
        "utils.plot_correlated_features(correlated_feature_batch, title=\"Correlated feature pairs: should always co-occur\")\n",
        "utils.plot_correlated_features(anticorrelated_feature_batch, title=\"Anti-correlated feature pairs: should never co-occur\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoHAQLUb5DS6"
      },
      "source": [
        "Now, let's try training our model & visualising features in 2D, when we have 2 pairs of correlated features (matching the [first row of the correlation figure](https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization) in the Anthropic paper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzdACaa2vw-p"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=5, n_features=4, d_hidden=2, n_correlated_pairs=2)\n",
        "\n",
        "# All same importance, very low feature probabilities (ranging from 5% down to 0.25%)\n",
        "importance = t.ones(cfg.n_features, dtype=t.float, device=device)\n",
        "feature_probability = 400 ** -t.linspace(0.5, 1, cfg.n_inst)\n",
        "\n",
        "model = Model(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu6XaI_J2cKL"
      },
      "outputs": [],
      "source": [
        "utils.plot_features_in_2d(\n",
        "    model.W,\n",
        "    colors=[\"blue\"] * 2 + [\"limegreen\"] * 2,\n",
        "    title=\"Correlated feature sets are represented in local orthogonal bases\",\n",
        "    subplot_titles=[f\"1 - S = {i:.3f}\" for i in feature_probability],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FWQPBs95DS6"
      },
      "source": [
        "### Exercise - generate more correlated feature plots\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "\n",
        "It should just involve changing the parameters in your code above.\n",
        "```\n",
        "\n",
        "You should now reproduce the second and third rows from the paper's [correlation figure](https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization). You may not get exactly the same results as the paper, but they should still roughly match (e.g. you should see no antipodal pairs in the code above, but you should see at least some when you test the anticorrelated sets, even if not all of them are antipodal). You can look at the solutions colab to see some examples.\n",
        "\n",
        "<details>\n",
        "<summary>Question - for the anticorrelated feature plots, you'l have to increase the feature probability to something like ~10%, or else you won't always form antipodal pairs. Why do you think this is?</summary>\n",
        "\n",
        "If sparsity is small / feature prob is large, then interference between the two pairs of anticorrelated features is a problem. If two features from different pairs are in the same subspace (because they're antipodal) the model is more likely to keep looking for a better solution.\n",
        "\n",
        "On the other hand, if sparsity is very large / feature probability is close to zero, then the negative effect of interference is much smaller. So the difference in loss between the solutions where the antipodal pairs are / aren't the same as the anticorrelated pairs is much smaller, and the model is more likely to just settle on whichever solution it finds first.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj9hjOWhdLeP"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - generate more correlated feature plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOITT2m_evzt"
      },
      "source": [
        "See the [Colab notebook](https://colab.research.google.com/drive/1mHKZpkhYAr0WWAQo2Y6pXL08yNfJHOVx?usp=sharing) for some sample code & outputs for these plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTzBhMGj5DS6"
      },
      "source": [
        "# 3️⃣ TMS: Superposition in a Privileged Basis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4vSP5-45DS6"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "So far, we've explored superposition in a model without a privileged basis. We can rotate the hidden activations arbitrarily and, as long as we rotate all the weights, have the exact same model behavior. That is, for any ReLU output model with weights\n",
        "$W$, we could take an arbitrary orthogonal matrix $O$ and consider the model $W' = OW$. Since $(OW)^T(OW) = W^T W$, the result would be an identical model!\n",
        "\n",
        "Models without a privileged basis are elegant, and can be an interesting analogue for certain neural network representations which don't have a privileged basis – word embeddings, or the transformer residual stream. But we'd also (and perhaps primarily) like to understand neural network representations where there are neurons which do impose a privileged basis, such as transformer MLP layers or conv net neurons.\n",
        "\n",
        "Our goal in this section is to explore the simplest toy model which gives us a privileged basis. There are at least two ways we could do this: we could add an activation function or apply $L_1$ regularization to the hidden layer. We'll focus on adding an activation function, since the representation we are most interested in understanding is hidden layers with neurons, such as the transformer MLP layer.\n",
        "\n",
        "This gives us the following \"ReLU hidden layer\" model. It's the simplest one we can use which is still likely to give us a privileged basis; we just take our previous setup and apply ReLU to the hidden layer.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "h & =\\operatorname{ReLU}(W x) \\\\\n",
        "x^{\\prime} & =\\operatorname{ReLU}\\left(W^T h+b\\right)\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mek_9Pk5DS7"
      },
      "source": [
        "### Exercise - implement `NeuronModel`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "In this section, you'll replicate the [first set of results](https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating-setup-loss:~:text=model%20and%20a-,ReLU%20hidden%20layer%20model,-%3A) in the Anthropic paper on studying superposition in a privileged basis. To do this, you'll need a new `NeuronModel` class. It can inherit most methods from the `Model` class, but you'll need to redefine the `forward` method to include an intermediate ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5MCJA2I5DS7"
      },
      "outputs": [],
      "source": [
        "class NeuronModel(Model):\n",
        "    def forward(\n",
        "        self,\n",
        "        features: Float[Tensor, \"... instances features\"]\n",
        "    ) -> Float[Tensor, \"... instances features\"]:\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_neuron_model(NeuronModel)\n",
        "\n",
        "\n",
        "tests.test_neuron_model(NeuronModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qqhtNeH2cKM"
      },
      "source": [
        "Once you've passed these tests, you can run the cells below to train the model in the same way as before. We use just one instance, with zero sparsity and uniform importance.\n",
        "\n",
        "We also visualize the matrix $W$. In these plots, we make it so the top-row visualisation is of $W$ rather than $W^T W$ - we can get away with this now because (unlike before) the individual elements of $W$ *are* meaningful. We're working with a **privileged basis**, and $W$ connects features to basis-aligned neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijdzLwDBzj0i"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=7, n_features=10, d_hidden=5)\n",
        "\n",
        "importance = 0.75 ** t.arange(1, 1 + cfg.n_features)\n",
        "feature_probability = t.tensor([0.75, 0.35, 0.15, 0.1, 0.06, 0.02, 0.01])\n",
        "\n",
        "model = NeuronModel(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo42Zn3D2cKM"
      },
      "outputs": [],
      "source": [
        "utils.plot_features_in_Nd(\n",
        "    model.W,\n",
        "    height=600,\n",
        "    width=1000,\n",
        "    title=f\"Neuron model: {cfg.n_features=}, {cfg.d_hidden=}, I<sub>i</sub> = 0.75<sup>i</sup>\",\n",
        "    subplot_titles=[f\"1 - S = {i:.2f}\" for i in feature_probability.squeeze()],\n",
        "    neuron_plot=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf3J5psb5DS7"
      },
      "source": [
        "### Exercise - interpret these plots\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "The first row shows plots of $W$. The rows are features, the columns are hidden dimensions (neurons).\n",
        "\n",
        "The second row shows stacked weight plots: in other words, each column is a neuron, and the values in a column are the exposures of the features to that particular neuron. In these plots, each feature is colored differently based on its interference with other features (dark blue means the feature is orthogonal to all other features, and lighter colors means the sum of squared dot products with other features is large).\n",
        "\n",
        "What is your interpretation of these plots? You should discuss things like monosemanticity / polysemanticity and how this changes with increasing sparsity.\n",
        "\n",
        "<details>\n",
        "<summary>Explanation for some of these plots</summary>\n",
        "\n",
        "**Low sparsity / high feature probability**\n",
        "\n",
        "With very low sparsity (feature prob $\\approx 1$), we get no superposition: every feature is represented faithfully by a different one of the model's neurons, or not represented at all. In other words, we have **pure monosemanticity**.\n",
        "\n",
        "In the heatmaps, we see a diagonal plot (up to rearrangement of neurons), i.e. each of the 5 most important features has a corresponding neuron which detects that particular feature, and no other.\n",
        "\n",
        "In the bar charts, we see this monosemanticity represented: each neuron has just one feature exposed to it.\n",
        "\n",
        "**Medium sparsity / medium feature probability**\n",
        "\n",
        "At intermediate values, we get some monosemantic neurons, and some polysemantic ones. You should see reoccurring block patterns like these (up to rearrangements of rows and/or columns):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/three_two2.png\" width=\"130\">\n",
        "\n",
        "Can you see what geometric arrangements these correspond to? The answer is in the nested dropdown below.\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "The 3x2 block shows 3 features embedded in 2D space. Denoting the 3 features $i, j, k$ respectively, we can see that $j$ is represented along the direction $(1, 1)$ (orthogonal to the other two), and $i, k$ are represented as $(-1, 1)$ and $(1, -1)$ respectively (antipodal pairs).\n",
        "\n",
        "As for the 3x3 block, it's actually 3 of the 4 points from a regular tetrahedron! This hints at an important fact which we'll explore in the next (optional) set of exercises: **superposition results in features organizing themselves into geometric structures**, which often represent uniform polyhedra.\n",
        "\n",
        "</details>\n",
        "\n",
        "The bar chart shows some neurons are starting to become polysemantic, with exposures to more than one feature.\n",
        "\n",
        "**High sparsity / low feature probability**\n",
        "\n",
        "With high sparsity, all neurons are polysemantic, and most / all features are represented in some capacity. The neurons aren't orthogonal (since we have way more features than neurons), but they don't need to be orthogonal: we saw in earlier sections how high sparsity can allow us to represent more features than we had dimensions. The same is true in this case.\n",
        "\n",
        "Note - Anthropic [finds](https://transformer-circuits.pub/2022/toy_model/index.html#privileged-basis:~:text=The%20solutions%20are%20visualized%20below) that with very high sparsity, each feature will correspond to a pair of neurons. However, you may not find this for your own plots (I didn't!). This is because - as Anthropic mention - they trained many separate instances and took the ones with smallest loss, since these models proved more difficult to optimize than others in their toy model setup.\n",
        "\n",
        "Overall, it looks a great deal like there are **neuron-level phase changes from monosemantic to polysemantic** as we increase the sparsity, mirroring the feature phase changes we saw earlier.\n",
        "\n",
        "</details>\n",
        "\n",
        "Try playing around with different settings (sparsity, importance). What kind of results do you get?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9oqnWxQirud"
      },
      "source": [
        "### Exercise (optional) - replicate plots more faithfully\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 10-25 minutes on this exercise, if you choose to do it.\n",
        "```\n",
        "\n",
        "Anthropic mention in their paper that they trained 1000 instances and chose the ones which achieved lowest loss. This is why your results might have differed from theirs, especially when the sparsity is very high / feature probability is very low.\n",
        "\n",
        "Can you implement this \"choose lowest loss\" method in your own class? Some suggestions:\n",
        "\n",
        "* The most basic way would be to modify the `optimize` function to return the loss per instance, and also use a for loop to run several `optimize` calls & at the end give you the best instances for each different level of sparsity.\n",
        "* A much better way would be to train more instances at once (e.g. `N` instances per level of sparsity), then for each level of sparsity you can argmax over `N` at the end to get a single instance. This will be much faster (although you'll have to be careful not to train 1000 instances at once; your GPU might not support it!).\n",
        "* To get very fancy, you could even add another dimension to the weight matrices, corresponding to this `N` dimension you argmax over. Then this \"taking lowest-loss instance\" behavior will be automatic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx7HRrQA2cKN"
      },
      "source": [
        "## Computation in superposition\n",
        "\n",
        "The example above was interesting, but in some ways it was also limited. The key problem here is that **the model doesn't benefit from the ReLU hidden layer**. Adding a ReLU does encourage the model to have a privileged basis, but since the model is trying to reconstruct the input (i.e. the identity, which is a linear function) it doesn't actually need to use the ReLU, and it will try anything it can to circumvent it - including learning biases which shift all the neurons into a positive regime where they behave linearly. This is a mark against using this toy model to study superposition.\n",
        "\n",
        "To extend this point: we don't want to study boring linear functions like the identity, we want to study **how models perform (nonlinear) computation in superposition**. The MLP layer in a transformer isn't just a way to represent information faithfully and recover it; it's a way to perform computation on that information. So for this next section, we'll train a model to perform some non-linear computation. Specifically, we'll train our model to **compute the absolute value of inputs $x$**.\n",
        "\n",
        "Our data $x$ are now sampled from the range $[-1, 1]$ rather than $[0, 1]$ (otherwise calculating the absolute value would be equivalent to reconstructing the input). This is about as simple as a nonlinear function can get, since $abs(x)$ is equivalent to $\\operatorname{ReLU}(x) + \\operatorname{ReLU}(-x)$. But since it's nonlinear, we can be sure that the model has to use the hidden layer ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHcWSstg2cKN"
      },
      "source": [
        "### Exercise - implement `NeuronComputationModel`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 20-30 minutes on this exercise.\n",
        "```\n",
        "\n",
        "You should fill in the `NeuronComputationModel` class below. Specifically, you'll need to fill in the `forward`, `generate_batch` and `calculate_loss` methods. Some guidance:\n",
        "\n",
        "* The model's **forward function** is different - it has a ReLU hidden layer in its forward function (as described above & in the paper).\n",
        "* The model's **data** is different - see the discussion above. Your `generate_batch` function should be rewritten - it will be the same as the first version of this function you wrote (i.e. without correlations) except for one difference: the value is sampled uniformly from the range $[-1, 1]$ rather than $[0, 1]$.\n",
        "* The model's **loss function** is different. Rather than computing the importance-weighted $L_2$ error between the input $x$ and output $x'$, we're computing the importance-weighted $L_2$ error between $\\operatorname{abs}(x)$ and $x'$. This should just require changing one line. The `optimize` function can stay the same, but it will now be optimizing this new loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNA3JOHH2cKN"
      },
      "outputs": [],
      "source": [
        "class NeuronComputationModel(Model):\n",
        "    W1: Float[Tensor, \"inst d_hidden feats\"]\n",
        "    W2: Float[Tensor, \"inst feats d_hidden\"]\n",
        "    b_final: Float[Tensor, \"inst feats\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        cfg: Config,\n",
        "        feature_probability: float | Tensor = 1.0,\n",
        "        importance: float | Tensor = 1.0,\n",
        "        device=device,\n",
        "    ):\n",
        "        super(Model, self).__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        if isinstance(feature_probability, float):\n",
        "            feature_probability = t.tensor(feature_probability)\n",
        "        self.feature_probability = feature_probability.to(device).broadcast_to(\n",
        "            (cfg.n_inst, cfg.n_features)\n",
        "        )\n",
        "        if isinstance(importance, float):\n",
        "            importance = t.tensor(importance)\n",
        "        self.importance = importance.to(device).broadcast_to((cfg.n_inst, cfg.n_features))\n",
        "\n",
        "        self.W1 = nn.Parameter(nn.init.kaiming_uniform_(t.empty((cfg.n_inst, cfg.d_hidden, cfg.n_features))))\n",
        "        self.W2 = nn.Parameter(nn.init.kaiming_uniform_(t.empty((cfg.n_inst, cfg.n_features, cfg.d_hidden))))\n",
        "        self.b_final = nn.Parameter(t.zeros((cfg.n_inst, cfg.n_features)))\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, features: Float[Tensor, \"... inst feats\"]) -> Float[Tensor, \"... inst feats\"]:\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def generate_batch(self, batch_size) -> Tensor:\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def calculate_loss(\n",
        "        self,\n",
        "        out: Float[Tensor, \"batch instances features\"],\n",
        "        batch: Float[Tensor, \"batch instances features\"],\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_neuron_computation_model(NeuronComputationModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhSqR-gP2cKN"
      },
      "source": [
        "Once you've passed these tests, you can run the code below to make the same visualisation as above.\n",
        "\n",
        "You should see similar patterns: with very low sparsity most/all neurons are monosemantic, but more polysemantic neurons appear as sparsity increases (until all neurons are polysemantic). Another interesting observation: in the monosemantic (or mostly monosemantic) cases, for any given feature there will be some neurons which have positive exposures to that feature and others with negative exposure. This is because some neurons are representing the value $\\operatorname{ReLU}(x_i)$ and others are representing the value of $\\operatorname{ReLU}(-x_i)$ (as discussed above, we require both of these to compute the absolute value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcZApwlf2cKN"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=7, n_features=100, d_hidden=40)\n",
        "\n",
        "importance = 0.8 ** t.arange(1, 1 + cfg.n_features)\n",
        "feature_probability = t.tensor([1.0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001])\n",
        "\n",
        "model = NeuronComputationModel(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLhyWClo2cKN"
      },
      "outputs": [],
      "source": [
        "plot_features_in_Nd(\n",
        "    model.W1,\n",
        "    height = 800,\n",
        "    width = 1600,\n",
        "    title = f\"Neuron computation model: n_features = {n_features}, d_hidden = {d_hidden}, I<sub>i</sub> = 0.75<sup>i</sup>\",\n",
        "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in feature_probability.squeeze()],\n",
        "    neuron_plot = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm-QSMc12cKN"
      },
      "source": [
        "To further confirm that this is happening, we can color the values in the bar chart discretely by feature, rather than continuously by the polysemanticity of that feature. We'll use a feature probability of 50% for this visualisation, which is high enough to make sure each neuron is monosemantic. You should find that the input weights $W_1$ form pairs of antipodal neurons (i.e. ones with positive / negative exposures to that feature direction), but both of these neurons have positive output weights $W_2$ for that feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSnouZ282Kef"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_inst=7, n_features=100, d_hidden=40)\n",
        "\n",
        "importance = 0.8 ** t.arange(1, 1 + cfg.n_features)\n",
        "feature_probability = t.tensor([1.0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001])\n",
        "\n",
        "model = NeuronComputationModel(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    importance=importance[None, :],\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRJtGnv_2JqU"
      },
      "outputs": [],
      "source": [
        "utils.plot_features_in_Nd(\n",
        "    model.W1,\n",
        "    height=800,\n",
        "    width=1400,\n",
        "    title=f\"Neuron computation model: {cfg.n_features=}, {cfg.d_hidden=}, I<sub>i</sub> = 0.75<sup>i</sup>\",\n",
        "    subplot_titles=[f\"1 - S = {i:.3f}<br>\" for i in feature_probability.squeeze()],\n",
        "    neuron_plot=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HYPbeM52cKN"
      },
      "source": [
        "## Bonus - the asymmetric superposition motif\n",
        "\n",
        "In the [corresponding section](https://transformer-circuits.pub/2022/toy_model/index.html#computation-asymmetric-motif) of Anthropic's paper, they discuss a particular quirk of this toy model in detail. Their section explains it in more detail than we will here (including some visual explanations), but we'll provide a relatively brief explanation here.\n",
        "\n",
        "> When we increase sparsity in our model & start to get superposed features, we don't always have monosemantic neurons which each calculate either $\\operatorname{ReLU}(x_i)$ or $\\operatorname{ReLU}(-x_i)$ for some feature $i$. Instead, we sometimes have **asymmetric superposition, where a single neuron detects two different features $i$ and $j$, and stores these features with different magnitudes (assume the $W_1$ vector for feature $i$ is much larger). The $W_2$ vectors have flipped magnitudes (i.e. the vector for $j$ is much larger). When $i$ is present and $j$ is not, there's no problem, because the output for feature $i$ is `large * small` (correct size) and for $j$ is `small * small` (near zero). But when $j$ is present and $i$ is not, the output for feature $j$ is `small * large` (correct size) and for $i$ is `large * large` (much larger than it should be). In particular, this is bad when the sign of output for $i$ is positive. The model fixes this by repurposing another neuron to correct for the case when $j$ is present and $i$ is not. We omit the exact mechanism, but it takes advantage of the fact that the model has a ReLU at the very end, so it doesn't matter if output for a feature is very large and negative (the loss will be truncated at zero), but being large and positive is very bad.\n",
        "\n",
        "Read the linked section of the Anthropic paper for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMz09QSGedJ-"
      },
      "source": [
        "### Exercise - replicate the asymmetric superposition results\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Can you find a set of hyperparameters (importance, sparsity values, number of features and neurons) where this behaviour is observed?\n",
        "\n",
        "Note - we recommend sticking with 5000 optimization steps or fewer. Overtraining this model can cause the magnitudes of $W_1$ to collapse, and $W_2$ to get very large, which makes the plot harder to visually interpret.\n",
        "\n",
        "We've given you a utils function `plot_features_in_Nd_discrete` for you to visualize the results. It takes arguments `W1` and `W2` (for the two different weights matrices of your model) as well as `title` (a string) and `legend_names` (list of strings, which you can use to label the different importances within each instance). We've also given you some example code below - all you need to do is find the parameters and train the model.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Solution (set of values I found which produced this pattern)</summary>\n",
        "\n",
        "I used `n_features=6` and `d_hidden=10` as seen in Anthropic's diagram. Feature probabilities are all $0.25$. Importances are the same as in the example case above; $I_i = 0.8^i$. Around half the instances I trained with these parameters had at least one monosemantic neuron *and* at least one pair of neurons which showed this pattern.\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XAcge_U2cKN"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - replicate the asymmetric superposition results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVGayHHCezIP"
      },
      "source": [
        "See the [Colab solutions notebook](https://colab.research.google.com/drive/1mHKZpkhYAr0WWAQo2Y6pXL08yNfJHOVx?usp=sharing) for some sample code & outputs for these plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pb8p7Hh5DS8"
      },
      "source": [
        "## Summary - what have we learned?\n",
        "\n",
        "With toy models like this, it's important to make sure we take away generalizable lessons, rather than just details of the training setup.\n",
        "\n",
        "The core things to take away form this paper are:\n",
        "\n",
        "* What superposition is\n",
        "* How it varies over feature importance and sparsity\n",
        "* How it varies when we have correlated or anticorrelated features\n",
        "* The difference between neuron and bottleneck superposition (or equivalently \"computational and representational supervision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnaswYse5DS9"
      },
      "source": [
        "# 4️⃣ Feature Geometry\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8AT1cvzxAUB"
      },
      "source": [
        "> Note - this section is optional, since it goes into quite extreme detail about the specific problem setup we're using here. If you want, you can jump to the next section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5-dTkz5DS9"
      },
      "source": [
        "## Dimensionality\n",
        "\n",
        "We've seen that superposition can allow a model to represent extra features, and that the number of extra features increases as we increase sparsity. In this section, we'll investigate this relationship in more detail, discovering an unexpected geometric story: features seem to organize themselves into geometric structures such as pentagons and tetrahedrons!\n",
        "\n",
        "The code below runs a third experiment, with all importances the same. We're first interested in the number of features the model has learned to represent. This is well represented with the squared **Frobenius norm** of the weight matrix $W$, i.e. $||W||_F^2 = \\sum_{ij}W_{ij}^2$.\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you see why this is a good metric for the number of features represented?</summary>\n",
        "\n",
        "By reordering the sums, we can show that the squared Frobenius norm is the sum of the squared norms of each of the 2D embedding vectors:\n",
        "\n",
        "$$\n",
        "\\big\\|W\\big\\|_F^2 = \\sum_j \\left(\\sum_i W_{ij}^2\\right) = \\sum_{j}\\big\\|W_{[:, j]}\\big\\|^2\n",
        "$$\n",
        "\n",
        "Each of these embedding vectors has squared norm approximately $1$ if a feature is represented, and $0$ if it isn't. So this is roughly the total number of represented features.\n",
        "</details>\n",
        "\n",
        "If you run the code below, you'll also plot the total number of \"dimensions per feature\", $m/\\big\\|W\\big\\|_F^2$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxByvek45DS9"
      },
      "outputs": [],
      "source": [
        "cfg = Config(n_features=200, d_hidden=20, n_inst=20)\n",
        "\n",
        "# For this experiment, use constant importance across features\n",
        "feature_probability = 20 ** -t.linspace(0, 1, cfg.n_inst)\n",
        "\n",
        "model = Model(\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    feature_probability=feature_probability[:, None],\n",
        ")\n",
        "model.optimize(steps=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJUe9ofL5DS9"
      },
      "outputs": [],
      "source": [
        "utils.plot_feature_geometry(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FlxC9395DS9"
      },
      "source": [
        "Surprisingly, we find that this graph is \"sticky\" at $1$ and $1/2$. On inspection, the $1/2$ \"sticky point\" seems to correspond to a precise geometric arrangement where features come in \"antipodal pairs\", each being exactly the negative of the other, allowing two features to be packed into each hidden dimension. It appears that antipodal pairs are so effective that the model preferentially uses them over a wide range of the sparsity regime.\n",
        "\n",
        "It turns out that antipodal pairs are just the tip of the iceberg. Hiding underneath this curve are a number of extremely specific geometric configurations of features.\n",
        "\n",
        "How can we discover these geometric configurations? Consider the following metric, which the authors named the **dimensionality** of a feature:\n",
        "\n",
        "$$\n",
        "D_i = \\frac{\\big\\|W_i\\big\\|^2}{\\sum_{j} \\big( \\hat{W_i} \\cdot W_j \\big)^2}\n",
        "$$\n",
        "\n",
        "Intuitively, this is a measure of what \"fraction of a dimension\" a specific feature gets. Let's try and get a few intuitions for this metric:\n",
        "\n",
        "* It's never less than zero.\n",
        "    * It's equal to zero if and only if the vector is the zero vector, i.e. the feature isn't represented.\n",
        "* It's never greater than one (because when $j = i$, the term in the denominator sum is equal to the numerator).\n",
        "    * It's equal to one if and only if the $i$-th feature vector $W_i$ is orthogonal to all other features (because then $j=i$ is the only term in the denominator sum).\n",
        "    * Intuitively, in this case the feature has an entire dimension to itself.\n",
        "* If there are $k$ features which are all parallel to each other, and orthogonal to all others, then they \"share\" the dimensionality equally, i.e. $D_i = 1/k$ for each of them.\n",
        "* The sum of all $D_i$ can't be greater than the total number of features $m$, with equality if and only if all the vectors are orthogonal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seKqykCl5DS-"
      },
      "source": [
        "### Exercise - compute dimensionality\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Remember, $W$ has shape `(n_inst, d_hidden, n_features)`. The vectors $W_i$ refer to the feature vectors (i.e. they have length `d_hidden`), and you should broadcast your calculations over the `n_inst` dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UML7S4Ap5DS-"
      },
      "outputs": [],
      "source": [
        "@t.inference_mode()\n",
        "def compute_dimensionality(W: Float[Tensor, \"n_inst d_hidden n_features\"]) -> Float[Tensor, \"n_inst n_features\"]:\n",
        "    pass\n",
        "\n",
        "\n",
        "tests.test_compute_dimensionality(compute_dimensionality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nht7vgIH5DS-"
      },
      "source": [
        "The code below plots the fractions of dimensions, as a function of increasing levels of sparsity across our instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KomeBaC5DS-"
      },
      "outputs": [],
      "source": [
        "W = model.W.detach()\n",
        "dim_fracs = compute_dimensionality(W)\n",
        "\n",
        "utils.plot_feature_geometry(model, dim_fracs=dim_fracs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM-DIe785DS_"
      },
      "source": [
        "What's going on here? It turns out that the model likes to create specific weight geometries and kind of jumps between the different configurations. For example:\n",
        "\n",
        "* With zero (or very small) sparsity, the feature basis isn't privileged by anything, and so the model represents features with arbitrary directions instead. There's no reason for some features to be represented faithfully and others not to be.\n",
        "* When we get to higher levels of sparsity, the feature basis becomes privileged. So the model phase-transitions to representing some features in antipodal pairs, and the rest aren't interpreted.\n",
        "* With further increases in sparsity, we transition to different geometries (see diagram below).\n",
        "\n",
        "The moral? Superposition is very hard to pin down! There are many points between a dimensionality of 0 (not learning a feature) and 1 (dedicating a dimension to a feature). As an analogy, we often think of water as only having three phases: ice, water and steam. But this is a simplification: there are actually many phases of ice, often corresponding to different crystal structures (eg. hexagonal vs cubic ice). In a vaguely similar way, neural network features seem to also have many other phases within the general category of \"superposition.\"\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/grid_all.png\" width=\"900\">\n",
        "\n",
        "Note that we should take care not to read too much significance into these results. A lot of it depends delicately on the details of our experimental setup (e.g. we used $W^T W$, a positive semidefinite matrix, and there's a correspondence between low-dimensional symmetric pos-semidef matrices like these and the kinds of polytopes that we've seen in the plots above). But hopefully this has given you a sense of the relevant considerations when it comes to packing features into fewer dimensions.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jd3LpCav3UXu",
        "0W0zgPVMw0XP",
        "oMUtONps5DS4",
        "fTzBhMGj5DS6",
        "EnaswYse5DS9",
        "2MD88v4Zvw-r",
        "triKEiX8AxRC"
      ],
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
