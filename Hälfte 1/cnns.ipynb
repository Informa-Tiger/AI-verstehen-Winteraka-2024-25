{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVsn9JeJLjC3"
      },
      "source": [
        "# CNNs & ResNets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E482P_ATLk-w"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST7GZ0xkxW6j"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/Fundamentals/main/images/cnn.png\" width=\"350\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd3LpCav3UXu"
      },
      "source": [
        "# Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyh3U2Q_sG9y"
      },
      "source": [
        "This section is designed to get you familiar with basic neural networks: how they are structured, the basic operations like linear layers and convolutions which go into making them, and why they work as well as they do. You'll start by making very simple neural networks, and by the end of today you'll build up to assembling ResNet34, a comparatively much more complicated architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGJzuxZsG9y"
      },
      "source": [
        "## Content & Learning Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJVhlvPlsG9y"
      },
      "source": [
        "### 1️⃣ Making your own modules\n",
        "\n",
        "In the first set of exercises, we'll cover the general structure of modules in PyTorch. You'll also implement your own basic modules, including for ReLU and Linear layers. You'll finish by assembling a very simple neural network.\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits\n",
        "\n",
        "### 2️⃣ Training Neural Networks\n",
        "\n",
        "Here, you'll learn how to write a training loop in PyTorch. We'll keep it simple for today (and later on we'll experiment with more modular and extensible designs).\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> - Understand how to work with transforms, datasets and dataloaders\n",
        "> - Understand the basic structure of a training loop\n",
        "> - Learn how to write your own validation loop\n",
        "\n",
        "### 3️⃣ Convolutions\n",
        "\n",
        "In this section, you'll read about convolutions, and implement them as an `nn.Module` (not from scratch; we leave that to the bonus exercises). You'll also learn about maxpooling, and implement that as well.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers\n",
        "\n",
        "### 4️⃣ ResNets\n",
        "\n",
        "Here, you'll combine all the pieces you've learned so far to assemble ResNet34, a much more complex architecture used for image classification.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation\n",
        "\n",
        "### 5️⃣ Bonus - Convolutions From Scratch\n",
        "\n",
        "This section takes you through the low-level details of how to actually implement convolutions. It's not necessary to understand this section to complete the exercises, but it's a good way to get a deeper understanding of how convolutions work.\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> * Understand how array strides work, and why they're important for efficient linear operations\n",
        "> * Learn how to use `as_strided` to perform simple linear operations like trace and matrix multiplication\n",
        "> * Implement your own convolutions and maxpooling functions using stride-based methods\n",
        "\n",
        "### 6️⃣ Bonus - Feature Extraction\n",
        "\n",
        "In this section, you'll learn how to repurpose your ResNet to perform a different task than it was designed for, using feature extraction.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand the difference between feature extraction and finetuning\n",
        "> * Perform feature extraction on a pre-trained ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcgAnZZOyBYk"
      },
      "source": [
        "## Setup (don't read, just run!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yYsYe32yl9U"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install packages\n",
        "    %pip install einops\n",
        "    %pip install jaxtyping\n",
        "\n",
        "    # Code to make sure output widgets display\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "    print(\"Imports & installations complete!\")\n",
        "\n",
        "else:\n",
        "    raise Exception(\"If running from VSCode, you should copy code from the Streamlit page, not the Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DRQ9j4ftyHXf"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from IPython.display import display\n",
        "from jaxtyping import Float, Int\n",
        "from typing import Dict\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# Get file paths to this set of exercises\n",
        "#exercises_dir = Path(\"chapter0_fundamentals/exercises\")\n",
        "#section_dir = exercises_dir / \"part2_cnns\"\n",
        "\n",
        "#from plotly_utils import imshow, line, bar\n",
        "#import part2_cnns.tests as tests\n",
        "#from part2_cnns.utils import print_param_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLj6KotcClq7"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test funcitons\n",
        "Execute this code block without reading it. Those funciton just test the behaviour of you later implementations agains the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def line(y_values, yaxis_range=None, labels=None, title=None, width=None):\n",
        "    \"\"\"\n",
        "    Simple line plot function similar to plotly's line\n",
        "    \n",
        "    Args:\n",
        "        y_values: list or array of values to plot\n",
        "        yaxis_range: tuple of (min, max) for y-axis range\n",
        "        labels: dict with 'x' and 'y' keys for axis labels\n",
        "        title: string for plot title\n",
        "        width: figure width in pixels (will be converted to inches)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    # Convert width from pixels to inches (assuming 100 DPI)\n",
        "    if width:\n",
        "        fig_width = width / 100\n",
        "        plt.figure(figsize=(fig_width, fig_width/2))\n",
        "    else:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "    \n",
        "    plt.plot(y_values)\n",
        "    \n",
        "    if yaxis_range:\n",
        "        plt.ylim(yaxis_range)\n",
        "    \n",
        "    if labels:\n",
        "        if 'x' in labels:\n",
        "            plt.xlabel(labels['x'])\n",
        "        if 'y' in labels:\n",
        "            plt.ylabel(labels['y'])\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    \n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_trace(trace_fn):\n",
        "    for n in range(10):\n",
        "        assert (\n",
        "            trace_fn(t.zeros((n, n), dtype=t.long)) == 0\n",
        "        ), f\"Test failed on zero matrix with size ({n}, {n})\"\n",
        "        assert (\n",
        "            trace_fn(t.eye(n, dtype=t.long)) == n\n",
        "        ), f\"Test failed on identity matrix with size ({n}, {n})\"\n",
        "        x = t.randint(0, 10, (n, n))\n",
        "        expected = t.trace(x)\n",
        "        actual = trace_fn(x)\n",
        "        assert actual == expected, f\"Test failed on randmly initialised matrix with size ({n}, {n})\"\n",
        "    print(\"All tests in `test_trace` passed!\")\n",
        "\n",
        "\n",
        "def test_mv(mv_fn):\n",
        "    mat = t.randn(3, 4)\n",
        "    vec = t.randn(4)\n",
        "    mv_actual = mv_fn(mat, vec)\n",
        "    mv_expected = mat @ vec\n",
        "    t.testing.assert_close(mv_actual, mv_expected)\n",
        "    print(\"All tests in `test_mv` passed!\")\n",
        "\n",
        "\n",
        "def test_mv2(mv_fn):\n",
        "    big = t.randn(30)\n",
        "    mat = big.as_strided(size=(3, 4), stride=(2, 4), storage_offset=8)\n",
        "    vec = big.as_strided(size=(4,), stride=(3,), storage_offset=8)\n",
        "    mv_actual = mv_fn(mat, vec)\n",
        "    mv_expected = mat @ vec\n",
        "    t.testing.assert_close(mv_actual, mv_expected)\n",
        "    print(\"All tests in `test_mv2` passed!\")\n",
        "\n",
        "\n",
        "def test_mm(mm_fn):\n",
        "    matA = t.randn(3, 4)\n",
        "    matB = t.randn(4, 5)\n",
        "    mm_actual = mm_fn(matA, matB)\n",
        "    mm_expected = matA @ matB\n",
        "    t.testing.assert_close(mm_actual, mm_expected)\n",
        "    print(\"All tests in `test_mm` passed!\")\n",
        "\n",
        "\n",
        "def test_mm2(mm_fn):\n",
        "    big = t.randn(30)\n",
        "    matA = big.as_strided(size=(3, 4), stride=(2, 4), storage_offset=8)\n",
        "    matB = big.as_strided(size=(4, 5), stride=(3, 2), storage_offset=8)\n",
        "    mm_actual = mm_fn(matA, matB)\n",
        "    mm_expected = matA @ matB\n",
        "    t.testing.assert_close(mm_actual, mm_expected)\n",
        "    print(\"All tests in `test_mm2` passed!\")\n",
        "\n",
        "\n",
        "def test_conv1d_minimal_simple(conv1d_minimal_simple, n_tests=5):\n",
        "    import numpy as np\n",
        "\n",
        "    for _ in range(n_tests):\n",
        "        h = np.random.randint(10, 30)\n",
        "        kernel_size = np.random.randint(1, 10)\n",
        "        x = t.randn((h,))\n",
        "        weights = t.randn((kernel_size,))\n",
        "        my_output = conv1d_minimal_simple(x, weights)\n",
        "        torch_output = t.conv1d(\n",
        "            x.unsqueeze(0).unsqueeze(0), weights.unsqueeze(0).unsqueeze(0), stride=1, padding=0\n",
        "        ).squeeze()\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_conv1d_minimal_simple` passed!\")\n",
        "\n",
        "\n",
        "def test_conv1d_minimal(conv1d_minimal, n_tests=20):\n",
        "    import numpy as np\n",
        "\n",
        "    for _ in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 30)\n",
        "        ci = np.random.randint(1, 5)\n",
        "        co = np.random.randint(1, 5)\n",
        "        kernel_size = np.random.randint(1, 10)\n",
        "        x = t.randn((b, ci, h))\n",
        "        weights = t.randn((co, ci, kernel_size))\n",
        "        my_output = conv1d_minimal(x, weights)\n",
        "        torch_output = t.conv1d(x, weights, stride=1, padding=0)\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_conv1d_minimal` passed!\")\n",
        "\n",
        "\n",
        "def test_conv2d_minimal(conv2d_minimal, n_tests=4):\n",
        "    \"\"\"\n",
        "    Compare against torch.conv2d.\n",
        "    Due to floating point rounding, they can be quite different in float32 but should be nearly identical in float64.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 300)\n",
        "        w = np.random.randint(10, 300)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        co = np.random.randint(1, 20)\n",
        "        kernel_size = tuple(np.random.randint(1, 10, size=(2,)))\n",
        "        x = t.randn((b, ci, h, w), dtype=t.float64)\n",
        "        weights = t.randn((co, ci, *kernel_size), dtype=t.float64)\n",
        "        my_output = conv2d_minimal(x, weights)\n",
        "        torch_output = t.conv2d(x, weights)\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_conv2d_minimal` passed!\")\n",
        "\n",
        "\n",
        "def test_conv1d(conv1d, n_tests=10):\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 300)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        co = np.random.randint(1, 20)\n",
        "        stride = np.random.randint(1, 5)\n",
        "        padding = np.random.randint(0, 5)\n",
        "        kernel_size = np.random.randint(1, 10)\n",
        "        x = t.randn((b, ci, h))\n",
        "        weights = t.randn((co, ci, kernel_size))\n",
        "        my_output = conv1d(x, weights, stride=stride, padding=padding)\n",
        "        torch_output = t.conv1d(x, weights, stride=stride, padding=padding)\n",
        "        t.testing.assert_close(my_output, torch_output, atol=1e-4, rtol=1e-4)\n",
        "    print(\"All tests in `test_conv1d` passed!\")\n",
        "\n",
        "\n",
        "def test_pad1d(pad1d):\n",
        "    \"\"\"Should work with one channel of width 4.\"\"\"\n",
        "    x = t.arange(4).float().view((1, 1, 4))\n",
        "    actual = pad1d(x, 1, 3, -2.0)\n",
        "    expected = t.tensor([[[-2.0, 0.0, 1.0, 2.0, 3.0, -2.0, -2.0, -2.0]]])\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    actual = pad1d(x, 1, 0, -2.0)\n",
        "    expected = t.tensor([[[-2.0, 0.0, 1.0, 2.0, 3.0]]])\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_pad1d` passed!\")\n",
        "\n",
        "\n",
        "def test_pad1d_multi_channel(pad1d):\n",
        "    \"\"\"Should work with two channels of width 2.\"\"\"\n",
        "    x = t.arange(4).float().view((1, 2, 2))\n",
        "    actual = pad1d(x, 0, 2, -3.0)\n",
        "    expected = t.tensor([[[0.0, 1.0, -3.0, -3.0], [2.0, 3.0, -3.0, -3.0]]])\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_pad1d_multi_channel` passed!\")\n",
        "\n",
        "\n",
        "def test_pad2d(pad2d):\n",
        "    \"\"\"Should work with one channel of 2x2.\"\"\"\n",
        "    x = t.arange(4).float().view((1, 1, 2, 2))\n",
        "    expected = t.tensor(\n",
        "        [\n",
        "            [\n",
        "                [\n",
        "                    [0.0, 0.0, 0.0],\n",
        "                    [0.0, 0.0, 0.0],\n",
        "                    [0.0, 1.0, 0.0],\n",
        "                    [2.0, 3.0, 0.0],\n",
        "                    [0.0, 0.0, 0.0],\n",
        "                    [0.0, 0.0, 0.0],\n",
        "                    [0.0, 0.0, 0.0],\n",
        "                ]\n",
        "            ]\n",
        "        ]\n",
        "    )\n",
        "    actual = pad2d(x, 0, 1, 2, 3, 0.0)\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_pad2d` passed!\")\n",
        "\n",
        "\n",
        "def test_pad2d_multi_channel(pad2d):\n",
        "    \"\"\"Should work with two channels of 2x1.\"\"\"\n",
        "    x = t.arange(4).float().view((1, 2, 2, 1))\n",
        "    expected = t.tensor(\n",
        "        [[[[-1.0, 0.0], [-1.0, 1.0], [-1.0, -1.0]], [[-1.0, 2.0], [-1.0, 3.0], [-1.0, -1.0]]]]\n",
        "    )\n",
        "    actual = pad2d(x, 1, 0, 0, 1, -1.0)\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_pad2d_multi_channel` passed!\")\n",
        "\n",
        "\n",
        "def test_conv2d(conv2d, n_tests=5):\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 300)\n",
        "        w = np.random.randint(10, 300)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        co = np.random.randint(1, 20)\n",
        "        stride = tuple(np.random.randint(1, 5, size=(2,)))\n",
        "        padding = tuple(np.random.randint(0, 5, size=(2,)))\n",
        "        kernel_size = tuple(np.random.randint(1, 10, size=(2,)))\n",
        "        x = t.randn((b, ci, h, w), dtype=t.float64)\n",
        "        weights = t.randn((co, ci, *kernel_size), dtype=t.float64)\n",
        "        my_output = conv2d(x, weights, stride=stride, padding=padding)\n",
        "        torch_output = t.conv2d(x, weights, stride=stride, padding=padding)\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_conv2d` passed!\")\n",
        "\n",
        "\n",
        "def test_maxpool2d(my_maxpool2d, n_tests=20):\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 50)\n",
        "        w = np.random.randint(10, 50)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        stride = None if np.random.random() < 0.5 else tuple(np.random.randint(1, 5, size=(2,)))\n",
        "        kernel_size = tuple(np.random.randint(1, 10, size=(2,)))\n",
        "        kH, kW = kernel_size\n",
        "        padding = np.random.randint(0, 1 + kH // 2), np.random.randint(0, 1 + kW // 2)\n",
        "        x = t.randn((b, ci, h, w))\n",
        "        my_output = my_maxpool2d(\n",
        "            x,\n",
        "            kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "        )\n",
        "        torch_output = t.max_pool2d(\n",
        "            x,\n",
        "            kernel_size,\n",
        "            stride=stride,  # type: ignore (None actually is allowed)\n",
        "            padding=padding,\n",
        "        )\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_maxpool2d` passed!\")\n",
        "\n",
        "\n",
        "def test_maxpool2d_module(MaxPool2d, n_tests=20, tuples=False):\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 50)\n",
        "        w = np.random.randint(10, 50)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        if tuples:\n",
        "            stride = None if np.random.random() < 0.5 else tuple(np.random.randint(1, 5, size=(2,)))\n",
        "            kernel_size = tuple(np.random.randint(1, 10, size=(2,)))\n",
        "            kH, kW = kernel_size\n",
        "            padding = np.random.randint(0, 1 + kH // 2), np.random.randint(0, 1 + kW // 2)\n",
        "        else:\n",
        "            stride = None if np.random.random() < 0.5 else np.random.randint(1, 5)\n",
        "            kernel_size = np.random.randint(1, 10)\n",
        "            padding = np.random.randint(0, 1 + kernel_size // 2)\n",
        "        x = t.randn((b, ci, h, w))\n",
        "        my_output = MaxPool2d(\n",
        "            kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "        )(x)\n",
        "\n",
        "        torch_output = nn.MaxPool2d(\n",
        "            kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "        )(x)\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_maxpool2d_module` passed!\")\n",
        "\n",
        "\n",
        "def compare_module_attributes(custom_module, reference_module):\n",
        "    module_name = custom_module.__class__.__name__\n",
        "\n",
        "    # Compare named parameters\n",
        "    custom_params = dict(custom_module.named_parameters())\n",
        "    ref_params = dict(reference_module.named_parameters())\n",
        "\n",
        "    assert list(custom_params.keys()) == list(ref_params.keys()), (\n",
        "        f\"Your {module_name} should declare the following parameters in order.\\n\"\n",
        "        f\"Expected: {list(ref_params.keys())}\\nActual: {list(custom_params.keys())}\"\n",
        "    )\n",
        "\n",
        "    # Check tensor shapes for parameters\n",
        "    for name in custom_params:\n",
        "        if hasattr(custom_params[name], \"shape\") and hasattr(ref_params[name], \"shape\"):\n",
        "            assert custom_params[name].shape == ref_params[name].shape, (\n",
        "                f\"Shape mismatch for parameter '{name}' in {module_name}.\\n\"\n",
        "                f\"Expected shape: {ref_params[name].shape}, Actual shape: {custom_params[name].shape}\"\n",
        "            )\n",
        "\n",
        "    # Compare named buffers\n",
        "    custom_buffers = dict(custom_module.named_buffers())\n",
        "    ref_buffers = dict(reference_module.named_buffers())\n",
        "\n",
        "    assert list(custom_buffers.keys()) == list(ref_buffers.keys()), (\n",
        "        f\"Your {module_name} should declare the following buffers in order.\\n\"\n",
        "        f\"Expected: {list(ref_buffers.keys())}\\nActual: {list(custom_buffers.keys())}\"\n",
        "    )\n",
        "\n",
        "    # Check tensor shapes for buffers\n",
        "    for name in custom_buffers:\n",
        "        if hasattr(custom_buffers[name], \"shape\") and hasattr(ref_buffers[name], \"shape\"):\n",
        "            assert custom_buffers[name].shape == ref_buffers[name].shape, (\n",
        "                f\"Shape mismatch for buffer '{name}' in {module_name}.\\n\"\n",
        "                f\"Expected shape: {ref_buffers[name].shape}, Actual shape: {custom_buffers[name].shape}\"\n",
        "            )\n",
        "\n",
        "\n",
        "def test_conv2d_module(Conv2d, n_tests=5, tuples=False):\n",
        "    \"\"\"\n",
        "    Your weight should be called 'weight' and have an appropriate number of elements.\n",
        "    \"\"\"\n",
        "    m = Conv2d(4, 5, 3)\n",
        "    assert isinstance(\n",
        "        m.weight, t.nn.parameter.Parameter\n",
        "    ), \"Weight should be registered a parameter!\"\n",
        "    assert m.weight.nelement() == 4 * 5 * 3 * 3\n",
        "    m_sol = nn.Conv2d(4, 5, 3, bias=False)\n",
        "    compare_module_attributes(m, m_sol)\n",
        "    import numpy as np\n",
        "\n",
        "    for i in range(n_tests):\n",
        "        b = np.random.randint(1, 10)\n",
        "        h = np.random.randint(10, 300)\n",
        "        w = np.random.randint(10, 300)\n",
        "        ci = np.random.randint(1, 20)\n",
        "        co = np.random.randint(1, 20)\n",
        "        if tuples:\n",
        "            stride = tuple(np.random.randint(1, 5, size=(2,)))\n",
        "            padding = tuple(np.random.randint(0, 5, size=(2,)))\n",
        "            kernel_size = tuple(np.random.randint(1, 10, size=(2,)))\n",
        "        else:\n",
        "            stride = np.random.randint(1, 5)\n",
        "            padding = np.random.randint(0, 5)\n",
        "            kernel_size = np.random.randint(1, 10)\n",
        "        x = t.randn((b, ci, h, w))\n",
        "        my_conv = Conv2d(\n",
        "            in_channels=ci, out_channels=co, kernel_size=kernel_size, stride=stride, padding=padding\n",
        "        )\n",
        "        my_output = my_conv(x)\n",
        "        torch_output = t.conv2d(x, my_conv.weight, stride=stride, padding=padding)\n",
        "        t.testing.assert_close(my_output, torch_output)\n",
        "    print(\"All tests in `test_conv2d_module` passed!\")\n",
        "\n",
        "\n",
        "def test_relu(ReLU):\n",
        "    x = t.randn(10) - 0.5\n",
        "    actual = ReLU()(x)\n",
        "    expected = F.relu(x)\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_relu` passed!\")\n",
        "\n",
        "\n",
        "def test_flatten(Flatten):\n",
        "    x = t.arange(24).reshape((2, 3, 4))\n",
        "    assert Flatten(start_dim=0)(x).shape == (24,)\n",
        "    assert Flatten(start_dim=1)(x).shape == (2, 12)\n",
        "    assert Flatten(start_dim=0, end_dim=1)(x).shape == (6, 4)\n",
        "    assert Flatten(start_dim=0, end_dim=-2)(x).shape == (6, 4)\n",
        "    print(\"All tests in `test_flatten` passed!\")\n",
        "\n",
        "\n",
        "def test_linear_forward(Linear, bias=False):\n",
        "    \"\"\"Your Linear should produce identical results to torch.nn given identical parameters.\"\"\"\n",
        "    x = t.rand((10, 512))\n",
        "    yours = Linear(512, 64, bias=bias)\n",
        "    official = t.nn.Linear(512, 64, bias=bias)\n",
        "    # ensure the weights are the same\n",
        "    yours.load_state_dict(official.state_dict())\n",
        "    actual = yours(x)\n",
        "    expected = official(x)\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_linear_forward` passed!\")\n",
        "\n",
        "\n",
        "def test_linear_parameters(Linear, bias=False):\n",
        "    l = Linear(2, 3, bias=bias)\n",
        "    l_sol = nn.Linear(2, 3, bias=bias)\n",
        "    compare_module_attributes(l, l_sol)\n",
        "    if not bias:\n",
        "        assert l.bias is None, \"Bias should be None when not enabled.\"\n",
        "    print(\"All tests in `test_linear_parameters` passed!\")\n",
        "\n",
        "class Solution_Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        '''\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "\n",
        "        sf = 1 / np.sqrt(in_features)\n",
        "\n",
        "        weight = sf * (2 * t.rand(out_features, in_features) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            bias = sf * (2 * t.rand(out_features,) - 1)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        x = einops.einsum(x, self.weight, \"... in_feats, out_feats in_feats -> ... out_feats\")\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # SOLUTION\n",
        "        # note, we need to use `self.bias is not None`, because `self.bias` is either a tensor or None, not bool\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
        "def test_linear_no_bias(Linear):\n",
        "    x = t.rand((10, 512))\n",
        "    yours = Linear(512, 64, bias=False)\n",
        "\n",
        "    assert yours.bias is None, \"Bias should be None when not enabled.\"\n",
        "    assert len(list(yours.parameters())) == 1\n",
        "\n",
        "    official = Solution_Linear(512, 64, bias=False)\n",
        "    yours.weight = official.weight\n",
        "    actual = yours(x)\n",
        "    expected = official(x)\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_linear_no_bias` passed!\")\n",
        "\n",
        "class Solution_SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28*28, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        return self.linear2(self.relu(self.linear1(self.flatten(x))))\n",
        "\n",
        "def test_mlp_module(SimpleMLP):\n",
        "    \n",
        "    mlp: nn.Module = SimpleMLP()\n",
        "    num_params = sum(p.numel() for p in mlp.parameters())\n",
        "    assert (\n",
        "        num_params == 79510\n",
        "    ), f\"Expected (28*28 + 1) * 100 + ((100 + 1) * 10) = 79510 parameters, got {num_params}\"\n",
        "    mlp_sol = Solution_SimpleMLP()\n",
        "    compare_module_attributes(mlp, mlp_sol)\n",
        "    print(\"All tests in `test_mlp_module` passed!\")\n",
        "\n",
        "\n",
        "def test_mlp_forward(SimpleMLP):\n",
        "    \n",
        "    mlp: nn.Module = SimpleMLP()\n",
        "    mlp_sol = Solution_SimpleMLP()()\n",
        "    x = t.rand((10, 28, 28))\n",
        "\n",
        "    # ensure the weights are the same\n",
        "    mlp.load_state_dict(mlp_sol.state_dict())\n",
        "\n",
        "    out = mlp(x)\n",
        "    out_sol = mlp_sol(x)\n",
        "    t.testing.assert_close(out, out_sol)\n",
        "    print(\"All tests in `test_mlp_forward` passed!\")\n",
        "class solution_BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"] # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        '''\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.weight = nn.Parameter(t.ones(num_features))\n",
        "        self.bias = nn.Parameter(t.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
        "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        # Calculating mean and var over all dims except for the channel dim\n",
        "        if self.training:\n",
        "            # Take mean over all dimensions except the feature dimension\n",
        "            # Using keepdim=True so we don't have to worry about broadasting them with x at the end\n",
        "            mean = t.mean(x, dim=(0, 2, 3), keepdim=True)\n",
        "            var = t.var(x, dim=(0, 2, 3), unbiased=False, keepdim=True)\n",
        "            # Updating running mean and variance, in line with PyTorch documentation\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.squeeze()\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var.squeeze()\n",
        "            self.num_batches_tracked += 1\n",
        "        else:\n",
        "            mean = einops.rearrange(self.running_mean, \"channels -> 1 channels 1 1\")\n",
        "            var = einops.rearrange(self.running_var, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "        # Rearranging these so they can be broadcasted (although there are other ways you could do this)\n",
        "        weight = einops.rearrange(self.weight, \"channels -> 1 channels 1 1\")\n",
        "        bias = einops.rearrange(self.bias, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "        return ((x - mean) / t.sqrt(var + self.eps)) * weight + bias\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # SOLUTION\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"num_features\", \"eps\", \"momentum\"]])\n",
        "\n",
        "def test_batchnorm2d_module(BatchNorm2d):\n",
        "    \"\"\"The public API of the module should be the same as the real PyTorch version.\"\"\"\n",
        "    num_features = 2\n",
        "    bn = BatchNorm2d(num_features)\n",
        "    assert bn.num_features == num_features\n",
        "    assert isinstance(\n",
        "        bn.weight, t.nn.parameter.Parameter\n",
        "    ), f\"weight has wrong type: {type(bn.weight)}\"\n",
        "    assert isinstance(bn.bias, t.nn.parameter.Parameter), f\"bias has wrong type: {type(bn.bias)}\"\n",
        "    assert isinstance(\n",
        "        bn.running_mean, t.Tensor\n",
        "    ), f\"running_mean has wrong type: {type(bn.running_mean)}\"\n",
        "    assert isinstance(\n",
        "        bn.running_var, t.Tensor\n",
        "    ), f\"running_var has wrong type: {type(bn.running_var)}\"\n",
        "    assert isinstance(\n",
        "        bn.num_batches_tracked, t.Tensor\n",
        "    ), f\"num_batches_tracked has wrong type: {type(bn.num_batches_tracked)}\"\n",
        "    bn_sol = solution_BatchNorm2d(num_features)\n",
        "    compare_module_attributes(bn, bn_sol)\n",
        "    print(\"All tests in `test_batchnorm2d_module` passed!\")\n",
        "\n",
        "\n",
        "def test_batchnorm2d_forward(BatchNorm2d):\n",
        "    \"\"\"For each channel, mean should be very close to 0 and std kinda close to 1 (because of eps).\"\"\"\n",
        "    num_features = 2\n",
        "    bn = BatchNorm2d(num_features)\n",
        "    assert bn.training\n",
        "    x = t.randn((100, num_features, 3, 4))\n",
        "    out = bn(x)\n",
        "    assert x.shape == out.shape\n",
        "    t.testing.assert_close(out.mean(dim=(0, 2, 3)), t.zeros(num_features))\n",
        "    t.testing.assert_close(out.std(dim=(0, 2, 3)), t.ones(num_features), atol=1e-3, rtol=1e-3)\n",
        "    print(\"All tests in `test_batchnorm2d_forward` passed!\")\n",
        "\n",
        "\n",
        "def test_batchnorm2d_running_mean(BatchNorm2d):\n",
        "    \"\"\"Over repeated forward calls with the same data in train mode, the running mean should converge to the actual mean.\"\"\"\n",
        "    bn = BatchNorm2d(3, momentum=0.6)\n",
        "    assert bn.training\n",
        "    x = t.arange(12).float().view((2, 3, 2, 1))\n",
        "    mean = t.tensor([3.5000, 5.5000, 7.5000])\n",
        "    num_batches = 30\n",
        "    for i in range(num_batches):\n",
        "        bn(x)\n",
        "        expected_mean = (1 - ((1 - bn.momentum) ** (i + 1))) * mean\n",
        "        t.testing.assert_close(bn.running_mean, expected_mean)\n",
        "    assert bn.num_batches_tracked.item() == num_batches\n",
        "\n",
        "    # Large enough momentum and num_batches -> running_mean should be very close to actual mean\n",
        "    bn.eval()\n",
        "    actual_eval_mean = bn(x).mean((0, 2, 3))\n",
        "    t.testing.assert_close(actual_eval_mean, t.zeros(3))\n",
        "    print(\"All tests in `test_batchnorm2d_running_mean` passed!\")\n",
        "\n",
        "\n",
        "def test_averagepool(AveragePool):\n",
        "    x = t.arange(24).reshape((1, 2, 3, 4)).float()\n",
        "    actual = AveragePool()(x)\n",
        "    expected = t.tensor([[5.5, 17.5]])\n",
        "    t.testing.assert_close(actual, expected)\n",
        "    print(\"All tests in `test_averagepool` passed!\")\n",
        "\n",
        "class Solution_ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "\n",
        "        self.left = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(out_feats)\n",
        "        )\n",
        "\n",
        "        if first_stride > 1:\n",
        "            self.right = Sequential(\n",
        "                Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride),\n",
        "                BatchNorm2d(out_feats)\n",
        "            )\n",
        "        else:\n",
        "            assert in_feats == out_feats\n",
        "            self.right = nn.Identity()\n",
        "\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        x_left = self.left(x)\n",
        "        x_right = self.right(x)\n",
        "        return self.relu(x_left + x_right)\n",
        "def test_residual_block(ResidualBlock):\n",
        "    \"\"\"\n",
        "    Test the user's implementation of `ResidualBlock`.\n",
        "    \"\"\"\n",
        "    # Create random input tensor\n",
        "    x = t.randn(1, 3, 64, 64)\n",
        "\n",
        "    # Instantiate both user and reference models\n",
        "    user_model = ResidualBlock(in_feats=3, out_feats=3)\n",
        "    ref_model = Solution_ResidualBlock(in_feats=3, out_feats=3)\n",
        "    # Check parameter count\n",
        "    user_params = sum(p.numel() for p in user_model.parameters())\n",
        "    ref_params = sum(p.numel() for p in ref_model.parameters())\n",
        "    # Special case this scenario because occasionally people will\n",
        "    # unconditionally create the right-hand branch and then only conditionally\n",
        "    # switch in the forward method whether to use the right-hand branch or not.\n",
        "    if user_params > ref_params:\n",
        "        error_message = f\"\"\"\n",
        "        When the first_stride=1, there are more parameters ({user_params}) than\n",
        "        expected ({ref_params}). Make sure that you don't create unnecessary\n",
        "        convolutions for the right-hand branch when first_stride=1. That is your\n",
        "        initialization code should only initialize the right-hand branch when\n",
        "        first_stride is not 1.\n",
        "        \"\"\"\n",
        "        raise AssertionError(error_message)\n",
        "    assert (\n",
        "        user_params == ref_params\n",
        "    ), f\"Parameter count mismatch (when first_stride=1). Expected {ref_params}, got {user_params}.\"\n",
        "    # Check forward function output is correct shape\n",
        "    user_output = user_model(x)\n",
        "    assert (\n",
        "        user_output.shape == (1, 3, 64, 64)\n",
        "    ), f\"Incorrect shape, expected (batch=1, out_feats=4, height=64, width=64), got {user_output.shape}\"\n",
        "    print(\"Passed all tests when first_stride=1\")\n",
        "\n",
        "    # Same checks, but now with nontrivial stride\n",
        "    user_model = ResidualBlock(in_feats=3, out_feats=4, first_stride=2)\n",
        "    ref_model = Solution_ResidualBlock(in_feats=3, out_feats=4, first_stride=2)\n",
        "    user_params = sum(p.numel() for p in user_model.parameters())\n",
        "    ref_params = sum(p.numel() for p in ref_model.parameters())\n",
        "    assert (\n",
        "        user_params == ref_params\n",
        "    ), f\"Parameter count mismatch (when first_stride>1). Expected {ref_params}, got {user_params}.\"\n",
        "    user_output = user_model(x)\n",
        "    assert (\n",
        "        user_output.shape == (1, 4, 32, 32)\n",
        "    ), f\"Incorrect shape, expected (batch=1, out_feats=4, height/first_stride=32, width/first_stride=32), got {user_output.shape}\"\n",
        "    print(\"Passed all tests when first_stride>1\")\n",
        "\n",
        "    print(\"All tests in `test_residual_block` passed!\")\n",
        "\n",
        "class solution_BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.'''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "\n",
        "        blocks = [ResidualBlock(in_feats, out_feats, first_stride)] + [\n",
        "            ResidualBlock(out_feats, out_feats) for n in range(n_blocks - 1)\n",
        "        ]\n",
        "        self.blocks = Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        return self.blocks(x)\n",
        "\n",
        "def test_block_group(BlockGroup):\n",
        "    \"\"\"\n",
        "    Test the user's implementation of `ResidualBlock`.\n",
        "    \"\"\"\n",
        "    # Create random input tensor\n",
        "    x = t.randn(1, 3, 64, 64)\n",
        "\n",
        "    # Instantiate both user and reference models\n",
        "    user_model = BlockGroup(n_blocks=2, in_feats=3, out_feats=3)\n",
        "    ref_model = solution_BlockGroup(n_blocks=2, in_feats=3, out_feats=3)\n",
        "    # Check parameter count\n",
        "    user_params = sum(p.numel() for p in user_model.parameters())\n",
        "    ref_params = sum(p.numel() for p in ref_model.parameters())\n",
        "    assert user_params == ref_params, \"Parameter count mismatch (when n_blocks=2, first_stride=1)\"\n",
        "    # Check forward function output is correct shape\n",
        "    user_output = user_model(x)\n",
        "    assert (\n",
        "        user_output.shape == (1, 3, 64, 64)\n",
        "    ), f\"Incorrect shape, expected (batch=1, out_feats=4, height=64, width=64), got {user_output.shape}\"\n",
        "    print(\"Passed all tests when first_stride=1\")\n",
        "\n",
        "    # Same checks, but now with nontrivial stride\n",
        "    user_model = BlockGroup(n_blocks=2, in_feats=3, out_feats=4, first_stride=2)\n",
        "    ref_model = solution_BlockGroup(n_blocks=2, in_feats=3, out_feats=4, first_stride=2)\n",
        "    user_params = sum(p.numel() for p in user_model.parameters())\n",
        "    ref_params = sum(p.numel() for p in ref_model.parameters())\n",
        "    assert user_params == ref_params, \"Parameter count mismatch (when n_blocks=2, first_stride>1)\"\n",
        "    user_output = user_model(x)\n",
        "    assert (\n",
        "        user_output.shape == (1, 4, 32, 32)\n",
        "    ), f\"Incorrect shape, expected (batch=1, out_feats=4, height/first_stride=32, width/first_stride=32), got {user_output.shape}\"\n",
        "    print(\"Passed all tests when first_stride>1\")\n",
        "\n",
        "    # Same checks, but now with a larger n_blocks\n",
        "    user_model = BlockGroup(n_blocks=5, in_feats=3, out_feats=4, first_stride=2)\n",
        "    ref_model = solution_BlockGroup(n_blocks=5, in_feats=3, out_feats=4, first_stride=2)\n",
        "    user_params = sum(p.numel() for p in user_model.parameters())\n",
        "    ref_params = sum(p.numel() for p in ref_model.parameters())\n",
        "    assert user_params == ref_params, \"Parameter count mismatch (when n_blocks=5, first_stride>1)\"\n",
        "    user_output = user_model(x)\n",
        "    assert (\n",
        "        user_output.shape == (1, 4, 32, 32)\n",
        "    ), f\"Incorrect shape, expected (batch=1, out_feats=4, height/first_stride=32, width/first_stride=32), got {user_output.shape}\"\n",
        "    print(\"Passed all tests when n_blocks>2\")\n",
        "\n",
        "    print(\"All tests in `test_block_group` passed!\")\n",
        "\n",
        "\n",
        "def test_get_resnet_for_feature_extraction(get_resnet_for_feature_extraction):\n",
        "    resnet: nn.Module = get_resnet_for_feature_extraction(10)\n",
        "\n",
        "    num_params = len(list(resnet.parameters()))\n",
        "\n",
        "    error_msg = (\n",
        "        \"\\nNote - make sure you've defined your resnet modules in the correct order (with the final linear layer last), \\\n",
        "otherwise this can cause issues for the test function.\"\n",
        "    )\n",
        "\n",
        "    # Check all gradients are correct\n",
        "    for i, (name, param) in enumerate(resnet.named_parameters()):\n",
        "        if i < num_params - 2:\n",
        "            assert not param.requires_grad, (\n",
        "                f\"Found param {name!r} before the final layer, which has requires_grad=True.\"\n",
        "                + error_msg\n",
        "            )\n",
        "        else:\n",
        "            assert param.requires_grad, (\n",
        "                f\"Found param {name!r} in the final layer, which has requires_grad=False.\"\n",
        "                + error_msg\n",
        "            )\n",
        "            if param.ndim == 2:\n",
        "                assert tuple(param.shape) == (10, 512), (\n",
        "                    f\"Expected final linear layer weights to have shape (n_classes=10, 512), instead found {tuple(param.shape)}\"\n",
        "                    + error_msg\n",
        "                )\n",
        "            else:\n",
        "                assert tuple(param.shape) == (10,), (\n",
        "                    f\"Expected final linear layer bias to have shape (n_classes=10,), instead found {tuple(param.shape)}\"\n",
        "                    + error_msg\n",
        "                )\n",
        "\n",
        "    print(\"All tests in `test_get_resnet_for_feature_extraction` passed!\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "def print_param_count(*models, display_df=True, use_state_dict=False):\n",
        "    \"\"\"\n",
        "    display_df: bool\n",
        "        If true, displays styled dataframe\n",
        "        if false, returns dataframe\n",
        "\n",
        "    use_state_dict: bool\n",
        "        If true, uses model.state_dict() to construct dataframe\n",
        "            This will include buffers, not just params\n",
        "        If false, uses model.named_parameters() to construct dataframe\n",
        "            This misses out buffers (more useful for GPT)\n",
        "    \"\"\"\n",
        "    df_list = []\n",
        "    gmap_list = []\n",
        "    for i, model in enumerate(models, start=1):\n",
        "        print(\n",
        "            f\"Model {i}, total params = {sum([param.numel() for name, param in model.named_parameters()])}\"\n",
        "        )\n",
        "        iterator = model.state_dict().items() if use_state_dict else model.named_parameters()\n",
        "        df = (\n",
        "            pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        f\"name_{i}\": name,\n",
        "                        f\"shape_{i}\": tuple(param.shape),\n",
        "                        f\"num_params_{i}\": param.numel(),\n",
        "                    }\n",
        "                    for name, param in iterator\n",
        "                ]\n",
        "            )\n",
        "            if (i == 1)\n",
        "            else pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        f\"num_params_{i}\": param.numel(),\n",
        "                        f\"shape_{i}\": tuple(param.shape),\n",
        "                        f\"name_{i}\": name,\n",
        "                    }\n",
        "                    for name, param in iterator\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "        df_list.append(df)\n",
        "        gmap_list.append(np.log(df[f\"num_params_{i}\"]))\n",
        "    df = df_list[0] if len(df_list) == 1 else pd.concat(df_list, axis=1).fillna(0)\n",
        "    for i in range(1, len(models) + 1):\n",
        "        df[f\"num_params_{i}\"] = df[f\"num_params_{i}\"].astype(int)\n",
        "    if len(models) > 1:\n",
        "        param_counts = [df[f\"num_params_{i}\"].values.tolist() for i in range(1, len(models) + 1)]\n",
        "        if all([param_counts[0] == param_counts[i] for i in range(1, len(param_counts))]):\n",
        "            print(\"All parameter counts match!\")\n",
        "        else:\n",
        "            print(\"Parameter counts don't match up exactly.\")\n",
        "    if display_df:\n",
        "        s = df.style\n",
        "        for i in range(1, len(models) + 1):\n",
        "            s = s.background_gradient(\n",
        "                cmap=\"viridis\", subset=[f\"num_params_{i}\"], gmap=gmap_list[i - 1]\n",
        "            )\n",
        "        with pd.option_context(\"display.max_rows\", 1000):\n",
        "            display(s)\n",
        "    else:\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmgIafL_7EUG"
      },
      "source": [
        "# 1️⃣ Making your own modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zGfJO-U7iD_"
      },
      "source": [
        "> ### Learning objectives\n",
        ">\n",
        "> - Learn how to create your own modules in PyTorch, by inheriting from `nn.Module`\n",
        "> - Assemble the pieces together to create a simple fully-connected network, to classify MNIST digits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQP9PYkh7jVu"
      },
      "source": [
        "## Subclassing `nn.Module`\n",
        "\n",
        "One of the most basic parts of PyTorch that you will see over and over is the `nn.Module` class. All types of neural net components inherit from it, from the simplest `nn.Relu` to the most complex `nn.Transformer`. Often, a complex `nn.Module` will have sub-`Module`s which implement smaller pieces of its functionality.\n",
        "\n",
        "Other common `Module`s  you'll see include\n",
        "\n",
        "- `nn.Linear`, for fully-connected layers with or without a bias\n",
        "- `nn.Conv2d`, for a two-dimensional convolution (we'll see more of these in a future section)\n",
        "- `nn.Softmax`, which implements the [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) function\n",
        "\n",
        "The list goes on, including activation functions, normalizations, pooling, attention, and more. You can see all the `Module`s that PyTorch provides [here](https://pytorch.org/docs/stable/nn.html). You can also create your own `Module`s, as we will do often!\n",
        "\n",
        "The `Module` class provides a lot of functionality, but we'll only cover a little bit of it here.\n",
        "\n",
        "In this section, we'll add another layer of abstraction to all the linear operations we've done in previous sections, by packaging them inside `nn.Module` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ltogr-l7lUZ"
      },
      "source": [
        "### `__init__` and `forward`\n",
        "\n",
        "A subclass of `nn.Module` usually looks something like this:\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        # Forward pass code\n",
        "```\n",
        "\n",
        "The initialization sets up attributes that will be used for the life of the `Module`, like its parameters, hyperparameters, or other sub-`Module`s it might need to use. These are usually added to the instance with something like `self.attribute = attr`, where `attr` might be provided as an argument. Some modules are simple enough that they don't need any persistent attributes, and in this case you can skip the `__init__`.\n",
        "\n",
        "The `forward` method is called on each forward pass of the `Module`, possibly using the attributes that were set up in the `__init__`. It should take in the input, do whatever it's supposed to do, and return the result. Subclassing `nn.Module` automatically makes instances of your class callable, so you can do `model(x)` on an input `x` to invoke the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDDBH7ZW7mn7"
      },
      "source": [
        "### The `nn.Parameter` class\n",
        "\n",
        "A `nn.Parameter` is a special type of `Tensor`. Basically, this is the class that torch has provided for storing the weights and biases of a `Module`. It has some special properties for doing this:\n",
        "\n",
        "- If a `Parameter` is set as an attribute of a `Module`, it will be auto-detected by torch and returned when you call `module.parameters()` (along with all the other `Parameters` associated with the `Module`, or any of the `Module`'s sub-modules!).\n",
        "- This makes it easy to pass all the parameters of a model into an optimizer and update them all at once.\n",
        "\n",
        "When you create a `Module` that has weights or biases, be sure to wrap them in `nn.Parameter` so that torch can detect and update them appropriately:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, weights: t.Tensor, biases: t.Tensor):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(weights) # wrapping a tensor in nn.Parameter\n",
        "        self.biases = nn.Parameter(biases)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPe4E7lu7oAB"
      },
      "source": [
        "### Printing information with `extra_repr`\n",
        "\n",
        "Another useful method is called `extra_repr`. This allows you to format the string representation of your `Module` in a way that's more informative than the default. For example, the following:\n",
        "\n",
        "```python\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, arg1, arg2, ...):\n",
        "        super().__init__()\n",
        "        # Initialization code\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"arg1={self.arg1}, arg2={self.arg2}, ...\"\n",
        "```\n",
        "\n",
        "will result in the output `\"MyModule(arg1=arg1, arg2=arg2, ...)\"` when you print an instance of this module. You might want to take this opportunity to print out useful invariant information about the module. The Python built-in function `getattr` might be helpful here (it can be used e.g. as `getattr(self, \"arg1\")`, which returns the same as `self.arg1` would). For simple modules, it's fine not to implement `extra_repr`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sHgF6En7o_F"
      },
      "source": [
        "## ReLU\n",
        "\n",
        "The first module you should implement is `ReLU`. This will relatively simple, since it doesn't involve any argument (so we only need to implement `forward`). Make sure you look at the PyTorch documentation page for [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) so that you're comfortable with what they do and why they're useful in neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OSobLjv7qJB"
      },
      "source": [
        "### Exercise - implement `ReLU`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "You should fill in the `forward` method of the `ReLU` class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBk1wLQw7rOG"
      },
      "outputs": [],
      "source": [
        "class ReLU(nn.Module):\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        return t.maximum(x, t.tensor(0.0))\n",
        "\n",
        "\n",
        "test_relu(ReLU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ZE1rrk7uh2"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "return t.maximum(x, t.tensor(0.0))\n",
        "```\n",
        "</details>\n",
        "\n",
        "## Linear\n",
        "\n",
        "Now implement your own `Linear` module. This applies a simple linear transformation, with a weight matrix and optional bias vector. The PyTorch documentation page is [here](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). Note that this is the first `Module` you'll implement that has learnable weights and biases.\n",
        "\n",
        "<details>\n",
        "<summary>Question - what type should these variables be?</summary>\n",
        "\n",
        "They have to be `torch.Tensor` objects wrapped in `nn.Parameter` in order for `nn.Module` to recognize them. If you forget to do this, `module.parameters()` won't include your `Parameter`, which prevents an optimizer from being able to modify it during training.\n",
        "        \n",
        "Also, in tomorrow's exercises we'll be building a ResNet and loading in weights from a pretrained model, and this is hard to do if you haven't registered all your parameters!\n",
        "</details>\n",
        "\n",
        "For any layer, initialization is very important for the stability of training: with a bad initialization, your model will take much longer to converge or may completely fail to learn anything. The default PyTorch behavior isn't necessarily optimal and you can often improve performance by using something more custom, but we'll follow it for today because it's simple and works decently well.\n",
        "\n",
        "Each float in the weight and bias tensors are drawn independently from the uniform distribution on the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{1}{\\sqrt{N_{in}}}, \\frac{1}{\\sqrt{N_{in}}}\\bigg]\n",
        "$$\n",
        "\n",
        "where $N_{in}$ is the number of inputs contributing to each output value. The rough intuition for this is that it keeps the variance of the activations at each layer constant, since each one is calculated by taking the sum over $N_{in}$ inputs multiplied by the weights (and standard deviation of the sum of independent random variables scales as the square root of number of variables).\n",
        "\n",
        "The name for this is **Kaiming (uniform) initialisation**.\n",
        "\n",
        "<details>\n",
        "<summary>Technical details (derivation of distribution)</summary>\n",
        "\n",
        "The key intuition behind Kaiming initialisation (and others like it) is that we want the variance of our activations to be the same through all layers of the model when we initialize. Suppose $x$ and $y$ are activations from two adjacent layers, and $w$ are the weights connecting them (so we have $y_i = \\sum_j w_{ij} x_j + b_i$, where $b$ is the bias). With $N_{x}$ as the number of neurons in layer $x$, we have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{Var}\\left(y_i\\right)=\\sigma_x^2 & =\\operatorname{Var}\\left(\\sum_j w_{i j} x_j\\right) \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j} x_j\\right) \\quad \\text { Inputs and weights are independent of each other } \\\\\n",
        "& =\\sum_j \\operatorname{Var}\\left(w_{i j}\\right) \\cdot \\operatorname{Var}\\left(x_j\\right) \\quad \\text { Variance of product of independent RVs with zero mean is product of variances } \\\\\n",
        "& = N_x \\cdot \\sigma_x^2 \\cdot \\operatorname{Var}\\left(w_{i j}\\right) \\quad \\text { Variance equal for all } N_x \\text { neurons, call this value } \\sigma_x^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "For this to be the same as $\\sigma_x^2$, we need $\\operatorname{Var}(w_{ij}) = \\frac{1}{N_x}$, so the standard deviation is $\\frac{1}{\\sqrt{N_x}}$.\n",
        "\n",
        "This is not exactly the case for the Kaiming uniform distribution (which has variance $\\frac{12}{(2 \\sqrt{N_x})^2} = \\frac{3}{N_x}$), and as far as I'm aware there's no principled reason why PyTorch does this. But the most important thing is that the variance scales as $O(1 / N_x)$, rather than what the exact scaling constant is.\n",
        "\n",
        "There are other initializations with some theoretical justification. For instance, **Xavier initialization** has a uniform distribution in the interval:\n",
        "\n",
        "$$\n",
        "\\bigg[-\\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}, \\frac{\\sqrt{6}}{\\sqrt{N_{in} + N_{out} + 1}}\\bigg]\n",
        "$$\n",
        "\n",
        "which is motivated by the idea of both keeping the variance of activations constant and keeping the ***gradients*** constant when we backpropagate.\n",
        "\n",
        "However, you don't need to worry about any of this here, just implement Kaiming He uniform with a bound of $\\frac{1}{\\sqrt{N_{in}}}$!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvmqP-K27wNf"
      },
      "source": [
        "### Exercise - implement `Linear`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Remember, you should define the weights (and bias, if appropriate) in the `__init__` block. Also, make sure not to mix up `bias` (which is the boolean parameter to `__init__`) and `self.bias` (which should either be the actual bias tensor, or `None` if `bias` is false)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upr0jDLx7yMh"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        '''\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        pass\n",
        "\n",
        "\n",
        "test_linear_parameters(Linear, bias=False)\n",
        "test_linear_parameters(Linear, bias=True)\n",
        "test_linear_forward(Linear, bias=False)\n",
        "test_linear_forward(Linear, bias=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk4vqA7I70Cs"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary>Help - when I print my Linear module, it also prints a large tensor.</summary>\n",
        "\n",
        "This is because you've (correctly) defined `self.bias` as either `torch.Tensor` or `None`, rather than set it to the boolean value of `bias` used in initialisation.\n",
        "        \n",
        "To fix this, you will need to change `extra_repr` so that it prints the boolean value of `bias` rather than the value of `self.bias`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
        "        '''\n",
        "        A simple linear (technically, affine) transformation.\n",
        "\n",
        "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
        "        If `bias` is False, set `self.bias` to None.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.bias = bias\n",
        "\n",
        "        sf = 1 / np.sqrt(in_features)\n",
        "\n",
        "        weight = sf * (2 * t.rand(out_features, in_features) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            bias = sf * (2 * t.rand(out_features,) - 1)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (*, in_features)\n",
        "        Return: shape (*, out_features)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        x = einops.einsum(x, self.weight, \"... in_feats, out_feats in_feats -> ... out_feats\")\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # SOLUTION\n",
        "        # note, we need to use `self.bias is not None`, because `self.bias` is either a tensor or None, not bool\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuICXMve7xYp"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Lastly, we'll implement `Flatten`. This is a standardised way to rearrange our tensors so that they can be fed into a linear layer. It's a bit like `einops.flatten`, but more specialised (we recommend you use the torch `reshape` method rather than `einops` for this exercise, although it is possible to use einops)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ5S4ovC8Zdf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dGN9rSP8aEw"
      },
      "source": [
        "### Exercise - implement `Flatten`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkzI7AfL8cbf"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, input: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        pass\n",
        "\n",
        "\n",
        "test_flatten(Flatten)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Mpbc7R8eQL"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I can't figure out what shape the output should be in Flatten.</summary>\n",
        "\n",
        "If `input.shape = (n0, n1, ..., nk)`, and the `Flatten` module has `start_dim=i, end_dim=j`, then the new shape should be `(n0, n1, ..., ni*...*nj, ..., nk)`. This is because we're **flattening** over the dimensions `(ni, ..., nj)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I can't see why my Flatten module is failing the tests.</summary>\n",
        "\n",
        "The most common reason is failing to correctly handle indices. Make sure that:\n",
        "* You're indexing up to **and including** `end_dim`.\n",
        "* You're correctly managing the times when `end_dim` is negative (e.g. if `input` is an nD tensor, and `end_dim=-1`, this should be interpreted as `end_dim=n-1`).\n",
        "</details>\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.start_dim = start_dim\n",
        "        self.end_dim = end_dim\n",
        "\n",
        "    def forward(self, input: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "\n",
        "        shape = input.shape\n",
        "\n",
        "        start_dim = self.start_dim\n",
        "        end_dim = self.end_dim if self.end_dim >= 0 else len(shape) + self.end_dim\n",
        "\n",
        "        shape_left = shape[:start_dim]\n",
        "        # shape_middle = t.prod(t.tensor(shape[start_dim : end_dim+1])).item()\n",
        "        shape_middle = functools.reduce(lambda x, y: x*y, shape[start_dim : end_dim+1])\n",
        "        shape_right = shape[end_dim+1:]\n",
        "\n",
        "        new_shape = shape_left + (shape_middle,) + shape_right\n",
        "\n",
        "        return t.reshape(input, new_shape)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"start_dim\", \"end_dim\"]])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Xp60208gg3"
      },
      "source": [
        "## Simple Multi-Layer Perceptron\n",
        "\n",
        "Now, we can put together these two modules to create a neural network. We'll create one of the simplest networks which can be used to separate data that is non-linearly separable: a single linear layer, followed by a nonlinear function (ReLU), followed by another linear layer. This type of architecture (alternating linear layers and nonlinear functions) is often called a **multi-layer perceptron** (MLP).\n",
        "\n",
        "The output of this network will have 10 dimensions, corresponding to the 10 classes of MNIST digits. We can then use the **softmax function** $x_i \\to \\frac{e^{x_i}}{\\sum_i e^{x_i}}$ to turn these values into probabilities. However, it's common practice for the output of a neural network to be the values before we take softmax, rather than after. We call these pre-softmax values the **logits**.\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you see what makes logits non-unique (i.e. why any given set of probabilities might correspond to several different possible sets of logits)?</summary>\n",
        "\n",
        "Logits are **translation invariant**. If you add some constant $c$ to all logits $x_i$, then the new probabilities are:\n",
        "\n",
        "$$\n",
        "p_i' = \\frac{e^{x_i + c}}{\\sum_j e^{x_j + c}} = \\frac{e^{x_i}}{\\sum_j e^{x_j}} = p_i\n",
        "$$\n",
        "\n",
        "in other words, the probabilities don't change.\n",
        "\n",
        "We can define **logprobs** as the log of the probabilities, i.e. $y_i = \\log p_i$. Unlike logits, these are uniquely defined.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy6th9SH8h17"
      },
      "source": [
        "### Exercise - implement the simple MLP\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to ~20 minutes on this exercise.\n",
        "```\n",
        "\n",
        "The diagram below shows what your MLP should look like:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/mlp-mermaid.svg\" width=\"170\">\n",
        "\n",
        "Please ask a TA (or message the Slack group) if any part of this diagram is unclear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddCsPsay8kVu"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        pass\n",
        "\n",
        "\n",
        "test_mlp_module(SimpleMLP)\n",
        "test_mlp_forward(SimpleMLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udDZbwye-EeL"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = Flatten()\n",
        "        self.linear1 = Linear(in_features=28*28, out_features=100)\n",
        "        self.relu = ReLU()\n",
        "        self.linear2 = Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        return self.linear2(self.relu(self.linear1(self.flatten(x))))\n",
        "\n",
        "```\n",
        "</details>\n",
        "In the next section, we'll learn how to train and evaluate our model on real data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59YGDI3p7FdX"
      },
      "source": [
        "# 2️⃣ Training Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui6zDqfl-GUh"
      },
      "source": [
        "## Transforms, Datasets & DataLoaders\n",
        "\n",
        "Before we use this model to make any predictions, we first need to think about our input data. Below is a block of code to fetch and process MNIST data. We will go through it line by line.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F48W9yU6E2Ms"
      },
      "outputs": [],
      "source": [
        "MNIST_TRANSFORM = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "def get_mnist(subset: int = 1):\n",
        "    '''Returns MNIST training data, sampled by the frequency given in `subset`.'''\n",
        "    mnist_trainset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=MNIST_TRANSFORM)\n",
        "    mnist_testset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=MNIST_TRANSFORM)\n",
        "\n",
        "    if subset > 1:\n",
        "        mnist_trainset = Subset(mnist_trainset, indices=range(0, len(mnist_trainset), subset))\n",
        "        mnist_testset = Subset(mnist_testset, indices=range(0, len(mnist_testset), subset))\n",
        "\n",
        "    return mnist_trainset, mnist_testset\n",
        "\n",
        "\n",
        "mnist_trainset, mnist_testset = get_mnist()\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "mnist_testloader = DataLoader(mnist_testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZnIpdLuE3_8"
      },
      "source": [
        "The `torchvision` package consists of popular datasets, model architectures, and common image transformations for computer vision. `transforms` is a library from `torchvision` which provides access to a suite of functions for preprocessing data.\n",
        "\n",
        "We define a transform for the MNIST data (which is applied to each image in the dataset) by composing `ToTensor` (which converts a `PIL.Image` object into a PyTorch tensor) and `Normalize` (which takes arguments for the mean and standard deviation, and performs the linear transformation `x -> (x - mean) / std`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11WFh4Q-WCa"
      },
      "source": [
        "Next, we define our datasets, using the `torchvision.datasets` library. The argument `root=\"./data\"` indicates that we're storing our data in the `./data` directory, and `transform=MNIST_TRANSFORM` tells us that we should apply our previously defined `transform` to each element in our dataset.\n",
        "\n",
        "The `Subset` function allows us to take a subset of a dataset. The argument `indices` is a list of indices to sample from the dataset. For example, `Subset(mnist_trainset, indices=[0, 1, 2])` will return a dataset containing only the first three elements of `mnist_trainset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcjIPO6H-X42"
      },
      "source": [
        "Finally, `DataLoader` provides a useful abstraction to work with a dataset. It takes in a dataset, and a few arguments including `batch_size` (how many inputs to feed through the model on which to compute the loss before each step of gradient descent) and `shuffle` (whether to randomise the order each time you iterate). The object that it returns can be iterated through as follows:\n",
        "\n",
        "```python\n",
        "for X, y in mnist_trainloader:\n",
        "    ...\n",
        "```\n",
        "\n",
        "where `X` is a 3D array of shape `(batch_size, 28, 28)` where each slice is an image, and `y` is a 1D tensor of labels of length `batch_size`. Without using this helpful object, we'd have to iterate through our dataset as follows:\n",
        "\n",
        "```python\n",
        "for i in range(len(mnist_trainset) // batch_size):\n",
        "    \n",
        "    X = mnist_trainset.data[i*batch_size: (i+1)*batch_size]\n",
        "    y = mnist_trainset.targets[i*batch_size: (i+1)*batch_size]\n",
        "\n",
        "    ...\n",
        "```\n",
        "\n",
        "A note about batch size - it's common to see batch sizes which are powers of two. The motivation is for efficient GPU utilisation, since processor architectures are normally organised around powers of 2, and computational efficiency is often increased by having the items in each batch split across processors. Or at least, that's the idea. The truth is a bit more complicated, and some studies dispute whether it actually saves time. We'll dive much deeper into these kinds of topics during the week on training at scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KskQlRbR-Zvd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvY7Y4P2-aVA"
      },
      "source": [
        "Before proceeding, try and answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - can you explain why we include a data normalization function in <code>torchvision.transforms</code> ?</summary>\n",
        "\n",
        "One consequence of unnormalized data is that you might find yourself stuck in a very flat region of the domain, and gradient descent may take much longer to converge.\n",
        "\n",
        "Normalization isn't strictly necessary for this reason, because any rescaling of an input vector can be effectively undone by the network learning different weights and biases. But in practice, it does usually help speed up convergence.\n",
        "\n",
        "Normalization also helps avoid numerical issues.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question - what is the benefit of using <code>shuffle=True</code> when defining our dataloaders? What might the problem be if we didn't do this?</summary>\n",
        "\n",
        "Shuffling is done during the training to make sure we aren't exposing our model to the same cycle (order) of data in every epoch. It is basically done to ensure the model isn't adapting its learning to any kind of spurious pattern.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fcLlMgX-b2r"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9un-Iu-cea"
      },
      "source": [
        "### Aside - `tqdm`\n",
        "\n",
        "You might have seen some blue progress bars running when you first downloaded your MNIST data. These were generated using a library called `tqdm`, which is also a really useful tool when training models or running any process that takes a long period of time.\n",
        "\n",
        "You can run the cell below to see how these progress bars are used (note that you might need to install the `tqdm` library first).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcfb6IvDLNK2"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    time.sleep(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL-JxP6MLL3A"
      },
      "source": [
        "`tqdm` wraps around a list, range or other iterable, but other than that it doesn't affect the structure of your loop.\n",
        "\n",
        "One gotcha when it comes to `tqdm` - you need to make sure you pass it something with a well-defined length. For instance, if you pass it an `enumerate` or `zip` object, it won't work as expected because it can't infer length from the object. You can fix this problem by wrapping your iterator in a list (e.g. `tqdm(list(zip(...)))`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5sbESFg-d2W"
      },
      "source": [
        "### Aside - `device`\n",
        "\n",
        "One last thing to discuss before we move onto training our model: **GPUs**. We'll discuss this in more detail in later exercises. For now, [this page](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk) should provide a basic overview of how to use your GPU. A few things to be aware of here:\n",
        "\n",
        "* The `to` method is really useful here - it can move objects between different devices (i.e. CPU and GPU) *as well as* changing a tensor's datatype.\n",
        "    * Note that `to` is never inplace for tensors (i.e. you have to call `x = x.to(device)`), but when working with models, calling `model = model.to(device)` or `model.to(device)` are both perfectly valid.\n",
        "* Errors from having one tensor on cpu and another on cuda are very common. Some useful practices to avoid this:\n",
        "    * Throw in assert statements, to make sure tensors are on the same device\n",
        "    * Remember that when you initialise an array (e.g. with `t.zeros` or `t.arange`), it will be on CPU by default.\n",
        "    * Tensor methods like [`new_zeros`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_zeros.html) or [`new_full`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_full.html) are useful, because they'll create tensors which match the device and dtype of the base tensor.\n",
        "\n",
        "It's common practice to put a line like this at the top of your file, defining a global variable which you can use in subsequent modules and functions (excluding the print statement):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YrSIwthvkSg"
      },
      "outputs": [],
      "source": [
        "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGinZFlb-f0h"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Below is a very simple training loop, which you can run to train your model.\n",
        "\n",
        "In later exercises, we'll try to **modularize** our training loops. This will involve things like creating a `Trainer` class which wraps around our model, and giving it methods like `training_step` and `validation_step` which correspond to different parts of the training loop. This will make it easier to add features like logging and validation, and will also make our code more readable and easier to refactor. However, for now we've kept things simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVpCJprY-hHv"
      },
      "outputs": [],
      "source": [
        "model = SimpleMLP().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 3\n",
        "\n",
        "mnist_trainset, _ = get_mnist(subset = 10)\n",
        "mnist_trainloader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "optimizer = t.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_list = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for imgs, labels in mnist_trainloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        logits = model(imgs)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "line(\n",
        "    loss_list,\n",
        "    yaxis_range=[0, max(loss_list) + 0.1],\n",
        "    labels={\"x\": \"Num batches seen\", \"y\": \"Cross entropy loss\"},\n",
        "    title=\"SimpleMLP training on MNIST\",\n",
        "    width=700\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Uh-HUN-ihe"
      },
      "source": [
        "Let's break down the important parts of this code.\n",
        "\n",
        "The batch size is the number of samples in each batch (i.e. the number of samples we feed into the model at once). While training our model, we differentiate with respect to the average loss over all samples in the batch (so a smaller batch usually means the loss is more noisy). However, if you're working with large models, then often having a batch size too large will result in a memory error. This will be relevant for models later on in the course, but for now we're working with very small models so this isn't an issue.\n",
        "\n",
        "Next, we get our training set, via the helper function `get_mnist`. This helper function used `torchvision.datasets.MNIST` to load in data, and then (optionally) the `torch.utils.data.Subset` function to return a subset of this data. Don't worry about the details of this function, it's not the kind of thing you'll need to know by heart.\n",
        "\n",
        "We then define our optimizer, using `torch.optim.Adam`. The `torch.optim` module gives a wide variety of modules, such as Adam, SGD, and RMSProp. Adam is generally the most popular and seen as the most effective in the majority of cases. We'll discuss optimizers in more detail tomorrow, but for now it's enough to understand that the optimizer calculates the amount to update parameters by (as a function of those parameters' gradients, and sometimes other inputs), and performs this update step. The first argument passed to our optimizer is the parameters of our model (because these are the values that will be updated via gradient descent), and you can also pass keyword arguments to the optimizer which change its behaviour (e.g. the learning rate).\n",
        "\n",
        "Lastly, we have the actual training loop. We iterate through our training data, and for each batch we:\n",
        "\n",
        "1. Evaluate our model on the batch of data, to get the logits for our class predictions,\n",
        "2. Calculate the loss between our logits and the true class labels,\n",
        "3. Backpropagate the loss through our model (this step accumulates gradients in our model parameters),\n",
        "4. Step our optimizer, which is what actually updates the model parameters,\n",
        "5. Zero the gradients of our optimizer, ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kas4EG9V-kP8"
      },
      "source": [
        "### Cross entropy loss\n",
        "\n",
        "The formula for cross entropy loss over a batch of size $N$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "l &= \\frac{1}{N} \\sum_{n=1}^{N} l_n \\\\\n",
        "l_n &=-\\log p_{n, y_{n}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $p_{n, c}$ is the probability the model assigns to class $c$ for sample $n$, and $y_{n}$ is the true label for this sample.\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're still confused about this formula, and how this relates to the information-theoretic general formula for cross entropy.</summary>\n",
        "\n",
        "The cross entropy of a distribution $p$ relate to a distribution $q$ is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H(q, p) &= -\\sum_{n} q(n) \\log p(n)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In our case, $q$ is the true distribution (i.e. the one-hot encoded labels, which equals one for $n = y_n$, zero otherwise), and $p$ is our model's output. With these subsitutions, this formula becomes equivalent to the formula for $l$ given above.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>See this dropdown, if you're confused about how this is the same as the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\">PyTorch definition</a>.</summary>\n",
        "\n",
        "The PyTorch definition of cross entropy loss is:\n",
        "\n",
        "$$\n",
        "\\ell(x, y)=\\frac{1}{N}\\sum_{n=1}^{N} l_n, \\quad l_n=-\\sum_{c=1}^C w_c \\log \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)} y_{n, c}\n",
        "$$\n",
        "\n",
        "$w_c$ are the weights (which all equal one by default), $p_{n, c} = \\frac{\\exp \\left(x_{n, c}\\right)}{\\sum_{i=1}^C \\exp \\left(x_{n, i}\\right)}$ are the probabilities, and $y_{n, c}$ are the true labels (which are one-hot encoded, i.e. their value is one at the correct label $c$ and zero everywhere else). With this, the formula for $l_n$ reduces to the one we see above (i.e. the mean of the negative log probabilities).\n",
        "\n",
        "</details>\n",
        "\n",
        "The function `torch.functional.cross_entropy` expects the **unnormalized logits** as its first input, rather than probabilities. We get probabilities from logits by applying the softmax function:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_{n, c} &= \\frac{\\exp(x_{n, c})}{\\sum_{c'=1}^{C} \\exp(x_{n, c'})}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $x_{n, c}$ is the model's output for class $c$ and sample $n$, and $C$ is the number of classes (in the case of MNIST, $C = 10$).\n",
        "\n",
        "Some terminology notes:\n",
        "\n",
        "* When we say **logits**, we mean the output of the model before applying softmax. We can uniquely define a distribution with a set of logits, just like we can define a distribution with a set of probabilities (and sometimes it's easier to think of a distribution in terms of logits, as we'll see later in the course).\n",
        "\n",
        "* When we say **unnormalized**, we mean the denominator term $\\sum_{c'} \\exp(x_{n, c'})$ isn't necessarily equal to 1. We can add a constant value onto all the logits which makes this term 1 without changing any of the actual probabilities, then we have the relation $p_{n, c} = \\exp(-l_{n, c})$. Here, we call $-l_{n, c}$ the **log probabilities** (or log probs), since $-l_{n, c} = \\log p_{n, c}$.\n",
        "\n",
        "If you're interested in the intuition behind cross entropy as a loss function, see [this post on KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence) (note that KL divergence and cross entropy differ by an amount which is independent of our model's predictions, so minimizing cross entropy is equivalent to minimizing KL divergence). Also see these two videos:\n",
        "\n",
        "* [Intuitively Understanding the Cross Entropy Loss](https://www.youtube.com/watch?v=Pwgpl9mKars&amp;ab_channel=AdianLiusie)\n",
        "* [Intuitively Understanding the KL Divergence](https://www.youtube.com/watch?v=SxGYPqCgJWM&amp;ab_channel=AdianLiusie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biTzObCR-lmw"
      },
      "source": [
        "### Aside - `dataclasses`\n",
        "\n",
        "Sometimes, when we have a lot of different input parameters to our model, it can be helpful to use dataclasses to keep track of them all. Dataclasses are a special kind of class which come with built-in methods for initialising and printing (i.e. no need to define an `__init__` or `__repr__`). Another advantage of using them is autocompletion: when you type in `args.` in VSCode, you'll get a dropdown of all your different dataclass attributes, which can be useful when you've forgotten what you called a variable!\n",
        "\n",
        "Here's an example of how we might rewrite our training code above using dataclasses. We've wrapped all the training code inside a single argument called `train`, which takes a `SimpleMLPTrainingArgs` object as its only argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlL1kSbr-nPw"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class SimpleMLPTrainingArgs():\n",
        "    '''\n",
        "    Defining this class implicitly creates an __init__ method, which sets arguments as\n",
        "    given below, e.g. self.batch_size = 64. Any of these arguments can also be overridden\n",
        "    when you create an instance, e.g. args = SimpleMLPTrainingArgs(batch_size=128).\n",
        "    '''\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    learning_rate: float = 1e-3\n",
        "    subset: int = 10\n",
        "\n",
        "\n",
        "def train(args: SimpleMLPTrainingArgs):\n",
        "    '''\n",
        "    Trains the model, using training parameters from the `args` object.\n",
        "    '''\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, _ = get_mnist(subset=args.subset)\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in tqdm(range(args.epochs)):\n",
        "        for imgs, labels in mnist_trainloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "    line(\n",
        "        loss_list,\n",
        "        yaxis_range=[0, max(loss_list) + 0.1],\n",
        "        labels={\"x\": \"Num batches seen\", \"y\": \"Cross entropy loss\"},\n",
        "        title=\"SimpleMLP training on MNIST\",\n",
        "        width=700\n",
        "    )\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "train(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQw6lskQ-rCj"
      },
      "source": [
        "### Exercise - add a validation loop\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵🔵\n",
        "\n",
        "You should spend up to ~20 minutes on this exercise.\n",
        "\n",
        "It is very important that you understand training loops and how they work, because we'll be doing a lot of model training in this way.\n",
        "```\n",
        "\n",
        "Edit the `train` function above to include a validation loop. Train your model, making sure you measure the accuracy at the end of each epoch.\n",
        "\n",
        "Here are a few tips to help you:\n",
        "\n",
        "* During the validation step, you should be measuring **accuracy**, which is defined as **the fraction of correctly classified images**.\n",
        "    * Note that (unlike loss) accuracy should only be logged after you've gone through the whole validation set. This is because your model doesn't update between computing different accuracies, so it doesn't make sense to log all of them separately.\n",
        "* You don't need to convert to probabilities before calculating accuracy (or even to logprobs), because softmax is an order-preserving function.\n",
        "* You can wrap your code in `with t.inference_mode():` to make sure that your model is in inference mode during validation (i.e. gradients don't propagate).\n",
        "    * Note you could also use the decorator `@t.inference_mode()` to do this, if your training loop was a function.\n",
        "* The `get_mnist` function returns both a trainset and a testset. In the `train` function above we only used the first one, but you should use both.\n",
        "* You'll need a dataloader for the testset, just like we did for the trainset. It doesn't matter whether you shuffle the testset or not, because we're not updating our model parameters during validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgsv8rPG-sLS"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - add a validation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfyUq0vw-yLZ"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to measure correct classifications.</summary>\n",
        "\n",
        "You can take argmax of the output of your model, using `torch.argmax` (with the keyword argument `dim` to specify the dimension you want to take max over).\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I get <code>RuntimeError: expected scalar type Float but found Byte</code>.</summary>\n",
        "\n",
        "This is commonly because one of your operations is between tensors with the wrong datatypes (e.g. `int` and `float`). Try navigating to the error line and checking your dtypes (or using VSCode's built-in debugger).\n",
        "</details>\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train(args: SimpleMLPTrainingArgs):\n",
        "    '''\n",
        "    Trains the model, using training parameters from the `args` object.\n",
        "    '''\n",
        "    model = SimpleMLP().to(device)\n",
        "\n",
        "    mnist_trainset, mnist_testset = get_mnist(subset=args.subset)\n",
        "    mnist_trainloader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    mnist_testloader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = t.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in tqdm(range(args.epochs)):\n",
        "\n",
        "        # Training loop\n",
        "        for imgs, labels in mnist_trainloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "        # Validation loop\n",
        "        num_correct_classifications = 0\n",
        "        for imgs, labels in mnist_testloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            with t.inference_mode():\n",
        "                logits = model(imgs)\n",
        "            predictions = t.argmax(logits, dim=1)\n",
        "            num_correct_classifications += (predictions == labels).sum().item()\n",
        "        accuracy = num_correct_classifications / len(mnist_testset)\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "    line(\n",
        "        loss_list,\n",
        "        yaxis_range=[0, max(loss_list) + 0.1],\n",
        "        x=t.linspace(0, args.epochs, len(loss_list)),\n",
        "        labels={\"x\": \"Num epochs\", \"y\": \"Cross entropy loss\"},\n",
        "        title=\"SimpleMLP training on MNIST\",\n",
        "        width=700,\n",
        "    )\n",
        "    line(\n",
        "        [0.1] + accuracy_list,  # starts with uniform accuracy\n",
        "        yaxis_range=[0, 1],\n",
        "        x=t.linspace(0, args.epochs, len(accuracy_list) + 1),\n",
        "        labels={\"x\": \"Num epochs\", \"y\": \"Accuracy\"},\n",
        "        title=\"SimpleMLP test accuracy on MNIST\",\n",
        "        width=700,\n",
        "    )\n",
        "\n",
        "\n",
        "args = SimpleMLPTrainingArgs()\n",
        "train(args)\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9OP8Ag6-zJh"
      },
      "source": [
        "\n",
        "You should find that after the first epoch, the model is already doing much better than random chance, and it improves slightly in subsequent epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiUVKtaD7HuH"
      },
      "source": [
        "# 3️⃣ Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSrbH46-0QP"
      },
      "source": [
        "> ### Learning Objectives\n",
        ">\n",
        "> * Learn how convolutions work, and why they are useful for vision models\n",
        "> * Implement your own convolutions, and maxpooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRmZru0-3Nu"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA) by 3Blue1Brown\n",
        "* [A Comprehensive Guide to Convolutional Neural Networks (TowardsDataScience)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz3jzRft-5c7"
      },
      "source": [
        "## Convolutions\n",
        "\n",
        "Here are some questions about convolutions to make sure you've understood the material. Once you finish the article above, you should try and answer these questions without referring back to the original article.\n",
        "\n",
        "<details>\n",
        "<summary>Why would convolutional layers be less likely to overfit data than standard linear (fully connected) layers?</summary>\n",
        "\n",
        "Convolutional layers require significantly fewer weights to be learned. This is because the same kernel is applied all across the image, rather than every pair of `(input, output)` nodes requiring a different weight to be learned.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Suppose you fixed some random permutation of the pixels in an image, and applied this to all images in your dataset, before training a convolutional neural network for classifying images. Do you expect this to be less effective, or equally effective?</summary>\n",
        "\n",
        "It will be less effective, because CNNs work thanks to **spatial locality** - groups of pixels close together are more meaningful. For instance, CNNs will often learn convolutions at an early layer which recognise gradients or simple shapes. If you permute the pixels (even if you permute in the same way for every image), you destroy locality.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have a 28x28 image, and you apply a 3x3 convolution with stride 1, padding 1, what shape will the output be?</summary>\n",
        "\n",
        "It will be the same shape, i.e. `28x28`. In the post linked above, this is described as **same padding**. Tomorrow, we'll build an MNIST classifier which uses these convolutions.\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv2Io_aadwoj"
      },
      "source": [
        "A note on terminology - you might see docs and docstrings sometimes use `num_features`, sometimes use `channels`, and sometimes just `C`. Often these two terms interchangeable. Our neural network inputs will often be RGB images and so we will have `channels=3` corresponding to the 3 colors red/green/blue. As we pass our initial image through convolutional layers, the number of channels will change. In the context of convolutions, the number of features and number of channels usually refer to the same value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCWlpGwJ-61Z"
      },
      "source": [
        "### Exercise - implement `Conv2d`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to ~20 minutes on this exercise.\n",
        "\n",
        "Make sure you understand what operation is taking place here, and how the dimensions are changing.\n",
        "```\n",
        "\n",
        "Rather than implementing the `conv2d` function from scratch, we'll allow you to use `t.nn.functional.conv2d`. In the exercise below, you should use this function to implement the `nn.Conv2d` layer. In other words, you should:\n",
        "\n",
        "* Initialize the weights for the convolutional layer in the `__init__` function.\n",
        "    * You should look at the PyTorch page for `nn.Conv2d` [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) to understand what the shape of the weights should be.\n",
        "    * We assume `bias=False`, so the only `nn.Parameter` object we need to define is `weight`.\n",
        "    * You should use **uniform Xavier initialization**, which is described at the bottom of the `nn.Conv2d` docs (the bullet points under the **Variables** header).\n",
        "* Implement the `forward` method, which should apply the convolutional layer to the input.\n",
        "    * In other words, it should implement the `torch.nn.functional.conv2d` function (documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html)), using the weights and biases (and other layer parameters) that you initialized in `__init__`.\n",
        "* Fill in the `extra_repr` method, to print out the convolutional layer's parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIxmCK0O--SW"
      },
      "outputs": [],
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0\n",
        "    ):\n",
        "        '''\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''Apply the functional conv2d, which you can import.'''\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        pass\n",
        "\n",
        "\n",
        "test_conv2d_module(Conv2d)\n",
        "m = Conv2d(in_channels=24, out_channels=12, kernel_size=3, stride=2, padding=1)\n",
        "print(f\"Manually verify that this is an informative repr: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLMoCNt0-_tD"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I don't know what to use as number of inputs, when doing Xavier initialisation.</summary>\n",
        "\n",
        "In the case of convolutions, each value in the output is computed by taking the product over `in_channels * kernel_width * kernel_height` elements. So this should be our value for $N_{in}$.\n",
        "</details>\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0\n",
        "    ):\n",
        "        '''\n",
        "        Same as torch.nn.Conv2d with bias=False.\n",
        "\n",
        "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        kernel_height = kernel_width = kernel_size\n",
        "        sf = 1 / np.sqrt(in_channels * kernel_width * kernel_height)\n",
        "        weight = sf * (2 * t.rand(out_channels, in_channels, kernel_height, kernel_width) - 1)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''Apply the functional conv2d, which you can import.'''\n",
        "        # SOLUTION\n",
        "        return t.nn.functional.conv2d(x, self.weight, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # SOLUTION\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SwWo9OX_A5P"
      },
      "source": [
        "### Exercise - implement `MaxPool2d`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵⚪⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Next, you should implement `MaxPool2d`. This module is often applied after a convolutional layer, to reduce the spatial dimensions of the output. It works by taking the maximum value in each kernel-sized window, and outputting that value. For instance, if we have a 2x2 kernel, then we take the maximum of each 2x2 window in the input.\n",
        "\n",
        "You should use `torch.nn.functional.max_pool2d` to implement this layer. The documentation page can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html), and the documentation for `nn.MaxPool2d` can be found [here](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTXDmJmr_CoH"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size: int, stride: int | None = None, padding: int = 1):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''Call the functional version of max_pool2d.'''\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        '''Add additional information to the string representation of this class.'''\n",
        "        pass\n",
        "\n",
        "\n",
        "test_maxpool2d_module(MaxPool2d)\n",
        "m = MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "print(f\"Manually verify that this is an informative repr: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfoClwI3_bpS"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size: int, stride: Optional[int] = None, padding: int = 1):\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''Call the functional version of maxpool2d.'''\n",
        "        # SOLUTION\n",
        "        return F.max_pool2d(x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        '''Add additional information to the string representation of this class.'''\n",
        "        # SOLUTION\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"kernel_size\", \"stride\", \"padding\"]])\n",
        "```\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm really confused about what to do here!</summary>\n",
        "\n",
        "Your `forward` method should just implement the `maxpool2d` function. In order to get the parameters for this function like `kernel_size` and `stride`, you'll need to initialise them in `__init__`.\n",
        "\n",
        "Remember that `MaxPool2d` has no weights - it's just a wrapper for the `maxpool2d` function.\n",
        "\n",
        "---\n",
        "\n",
        "Ideally, the `extra_repr` method should output something like:\n",
        "```python\n",
        "\"kernel_size=3, stride=2, padding=1\"\n",
        "```\n",
        "\n",
        "so that when you print the module, it will look like this:\n",
        "\n",
        "```python\n",
        "MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9NImreY7IZb"
      },
      "source": [
        "# 4️⃣ ResNets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8IZLzE0_gCS"
      },
      "source": [
        "> ### Learning Objectives\n",
        ">\n",
        "> * Learn about skip connections, and how they help overcome the degradation problem\n",
        "> * Learn about batch normalization, and why it is used in training\n",
        "> * Assemble your own ResNet, and load in weights from PyTorch's ResNet implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ZGesNI_hYQ"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* [Batch Normalization in Convolutional Neural Networks](https://www.baeldung.com/cs/batch-normalization-cnn)\n",
        "* [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "You should move on once you can answer the following questions:\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\"Batch Normalization allows us to be less careful about initialization.\" Explain this statement.</summary>\n",
        "\n",
        "Weight initialisation methods like Xavier (which we encountered yesterday) are based on the idea of making sure the activations have approximately the same distribution across layers at initialisation. But batch normalisation ensures that this is the case as signals pass through the network.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Give three reasons why batch norm improves the performance of neural networks.</summary>\n",
        "\n",
        "The reasons given in the first linked document above are:\n",
        "\n",
        "* Normalising inputs speeds up computation\n",
        "* Internal covariate shift is reduced, i.e. the mean and standard deviation is kept constant across the layers.\n",
        "* Regularisation effect: noise internal to each minibatch is reduced\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>If you have an input tensor of size (batch, channels, width, height), and you apply a batchnorm layer, how many learned parameters will there be?</summary>\n",
        "\n",
        "A mean and standard deviation is calculated for each channel (i.e. each calculation is done across the batch, width, and height dimensions). So the number of learned params will be `2 * channels`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>In the paper, the diagram shows additive skip connections (i.e. F(x) + x). One can also form concatenated skip connections, by \"gluing together\" F(x) and x into a single tensor. Give one advantage and one disadvantage of these, relative to additive connections.</summary>\n",
        "\n",
        "One advantage of concatenation: the subsequent layers can re-use middle representations; maintaining more information which can lead to better performance. Also, this still works if the tensors aren't exactly the same shape. One disadvantage: less compact, so there may be more weights to learn in subsequent layers.\n",
        "\n",
        "Crucially, both the addition and concatenation methods have the property of preserving information, to at least some degree of fidelity. For instance, you can [use calculus to show](https://theaisummer.com/skip-connections/#:~:text=residual%20skip%20connections.-,ResNet%3A%20skip%20connections%C2%A0via%C2%A0addition,-The%20core%20idea) that both methods will fix the vanishing gradients problem.\n",
        "</details>\n",
        "\n",
        "\n",
        "In this section, we'll do a more advanced version of the exercise in part 1. Rather than building a relatively simple network in which computation can be easily represented by a sequence of simple layers, we're going to build a more complex architecture which requires us to define nested blocks.\n",
        "\n",
        "We'll start by defining a few more `nn.Module` objects, which we hadn't needed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q94dxuju_jpr"
      },
      "source": [
        "## Sequential\n",
        "\n",
        "Firstly, now that we're working with large and complex architectures, we should create a version of `nn.Sequential`. As the name suggests, when an `nn.Sequential` is fed an input, it sequentially applies each of its submodules to the input, with the output from one module feeding into the next one.\n",
        "\n",
        "The implementation is given to you below. A few notes:\n",
        "\n",
        "* In initalization, we add to the `_modules` dictionary.\n",
        "    * This is a special type of dict called an **ordered dictionary**, which preserves the order of elements that get added (although Python sort-of does this now by default).\n",
        "    * When we call `self.parameters()`, this recursively goes through all modules in `self._modules`, and returns the params in those modules. This means we can nest sequentials within sequentials!\n",
        "* The special `__getitem__` and `__setitem__` methods determine behaviour when we get and set modules within the sequential.\n",
        "* The `repr` of the base class `nn.Module` already recursively prints out the submodules, so we don't need to write anything in `extra_repr`.\n",
        "    * To see how this works in practice, try defining a `Sequential` which takes a sequence of modules that you've defined above, and see what it looks like when you print it.\n",
        "\n",
        "Don't worry about deeply understanding this code. The main takeaway is that `nn.Sequential` is a useful list-like object to store modules, and apply them all sequentially.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - initializing Sequential with an OrderedDict</summary>\n",
        "\n",
        "The actual `nn.Sequential` module can be initialized with an ordered dictionary, rather than a list of modules. For instance, rather than doing this:\n",
        "\n",
        "```python\n",
        "seq = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 30)\n",
        ")\n",
        "```\n",
        "\n",
        "we can do this:\n",
        "\n",
        "```python\n",
        "seq = nn.Sequential(OrderedDict([\n",
        "    (\"linear1\", nn.Linear(10, 20)),\n",
        "    (\"relu\", nn.ReLU()),\n",
        "    (\"linear2\", nn.Linear(20, 30))\n",
        "]))\n",
        "```\n",
        "\n",
        "This is handy if we want to give each module an descriptive name.\n",
        "\n",
        "The `Sequential` implementation below doesn't allow the input to be an OrderedDict. As a bonus exercise, can you rewrite the `__init__`, `__getitem__` and `__setitem__` methods to allow the input to be an OrderedDict?\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW236Tbi_kwt"
      },
      "outputs": [],
      "source": [
        "class Sequential(nn.Module):\n",
        "    _modules: Dict[str, nn.Module]\n",
        "\n",
        "    def __init__(self, *modules: nn.Module):\n",
        "        super().__init__()\n",
        "        for index, mod in enumerate(modules):\n",
        "            self._modules[str(index)] = mod\n",
        "\n",
        "    def __getitem__(self, index: int) -> nn.Module:\n",
        "        index %= len(self._modules) # deal with negative indices\n",
        "        return self._modules[str(index)]\n",
        "\n",
        "    def __setitem__(self, index: int, module: nn.Module) -> None:\n",
        "        index %= len(self._modules) # deal with negative indices\n",
        "        self._modules[str(index)] = module\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''Chain each module together, with the output from one feeding into the next one.'''\n",
        "        for mod in self._modules.values():\n",
        "            x = mod(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjC8u9Pz_mF8"
      },
      "source": [
        "## BatchNorm2d\n",
        "\n",
        "Now, we'll implement our `BatchNorm2d`, the layer described in the documents you hopefully read above.\n",
        "\n",
        "Something which might have occurred to you as you read about batch norm - how does it work when in inference mode? It makes sense to normalize over a batch of multiple input data, but normalizing over a single datapoint doesn't make any sense! This is why we have to introduce a new PyTorch concept: **buffers**.\n",
        "\n",
        "Unlike `nn.Parameter`, a buffer is not its own type and does not wrap a `Tensor`. A buffer is just a regular `Tensor` on which you've called [self.register_buffer](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer) from inside a `nn.Module`. As an example, `self.register_buffer(\"variable_name\", t.zeros(10))` will define an object `self.variable_name` and register it as a buffer.\n",
        "\n",
        "What is a buffer, and why is it different to a standard attribute or to a `nn.Parameter` object? The differences are as follows:\n",
        "\n",
        "* It is normally included in the output of `module.state_dict()`, meaning that `torch.save` and `torch.load` will serialize and deserialize it.\n",
        "* It is moved between devices when you call `model.to(device)`.\n",
        "* It is not included in `module.parameters`, so optimizers won't see or modify it. Instead, your module will modify it as appropriate within `forward`.\n",
        "\n",
        "Implementation note: when defining BatchNorm2d, register_buffer lines must be **in order** and **after** initializing self.weight and self.bias (as the `copy_weights` function relies on order matching exactly)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oGSzB8K_njw"
      },
      "source": [
        "### Train and Eval Modes\n",
        "\n",
        "This is your first implementation that needs to care about the value of `self.training`, which is set to True by default, and can be set to False by `self.eval()` or to True by `self.train()`.\n",
        "\n",
        "In training mode, you should use the mean and variance of the batch you're on, but you should also update a stored `running_mean` and `running_var` on each call to `forward` using the \"momentum\" argument as described in the PyTorch docs. Your `running_mean` shuld be intialized as all zeros; your `running_var` should be initialized as all ones. Also, you should keep track of `num_batches_tracked`.\n",
        "\n",
        "<details>\n",
        "<summary>Aside on <code>num_batches_tracked</code> (optional, unimportant)</summary>\n",
        "\n",
        "PyTorch uses this to calculate momentum for calculation of the moving averages in the event that the module is intialized with `momentum=None`, although you don't need to worry about this because you can assume that the momentum parameter will always be a float in our use cases; we're just keeping track of `num_batches_tracked` to be consistent with PyTorch's version of BatchNorm2d, and to make sure that our state dictionaries have the same items.\n",
        "\n",
        "</details>\n",
        "\n",
        "In eval mode, you should use the running mean and variance that you stored before (not the mean and variance from the current batch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mgv9tNi_pHn"
      },
      "source": [
        "### Exercise - implement `BatchNorm2d`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 20-40 minutes on this exercise.\n",
        "\n",
        "This is the most challenging module you'll have implemented so far. Getting all the dimensions and operations right can be tricky.\n",
        "```\n",
        "\n",
        "Implement `BatchNorm2d` according to the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). Call your learnable parameters `weight` and `bias` for consistency with PyTorch.\n",
        "\n",
        "We're implementing it with `affine=True` and `track_running_stats=True`.\n",
        "\n",
        "A few tips (some of them are repeated from above):\n",
        "\n",
        "- Remember to differentiate between training mode, when `self.training=True` (you calculate mean & variance and update the running values) and eval mode, when `self.training=False` (you use the running values).\n",
        "- After you''ve normalized `x`, don't forget to multiply by `weight` and add `bias` (you might need to reshape these tensors so that they broadcast correctly).\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand which dimensions I should be taking the mean over.</summary>\n",
        "\n",
        "The input has shape `(batch, channels, height, width)` (where channels is synonymous with features). You want to calculate the mean and variance for each channel, meaning you should reduce over all dimensions except the first, e.g. `t.mean(x, dim=(0, 2, 3))`. You should then update the running mean and variance accordingly.\n",
        "\n",
        "Tip: use the argument `keepdim=True` in your mean and variance calculations, to make sure that the mean & variance still broadcast with the original input when you calculate `(x - mean) / std`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand what the formula for updating the running mean / variance should be.</summary>\n",
        "\n",
        "You want `running_mean <- (1 - momentum) * running_mean + momentum * new_mean`. Again, make sure you get the dimensions right - all the tensors in this operation should be 1D, with shape `(num_features,)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "If you're struggling with this implementation, we do recommend reading the solution, because there are lots of non-obvious ways this implementation can go wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddpDrKaN_qSn"
      },
      "outputs": [],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"] # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        '''\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        pass\n",
        "\n",
        "\n",
        "test_batchnorm2d_module(BatchNorm2d)\n",
        "test_batchnorm2d_forward(BatchNorm2d)\n",
        "test_batchnorm2d_running_mean(BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NB2SCy6_s54"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class BatchNorm2d(nn.Module):\n",
        "    # The type hints below aren't functional, they're just for documentation\n",
        "    running_mean: Float[Tensor, \"num_features\"]\n",
        "    running_var: Float[Tensor, \"num_features\"]\n",
        "    num_batches_tracked: Int[Tensor, \"\"] # This is how we denote a scalar tensor\n",
        "\n",
        "    def __init__(self, num_features: int, eps=1e-05, momentum=0.1):\n",
        "        '''\n",
        "        Like nn.BatchNorm2d with track_running_stats=True and affine=True.\n",
        "\n",
        "        Name the learnable affine parameters `weight` and `bias` in that order.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.weight = nn.Parameter(t.ones(num_features))\n",
        "        self.bias = nn.Parameter(t.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", t.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", t.ones(num_features))\n",
        "        self.register_buffer(\"num_batches_tracked\", t.tensor(0))\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Normalize each channel.\n",
        "\n",
        "        Compute the variance using `torch.var(x, unbiased=False)`\n",
        "        Hint: you may also find it helpful to use the argument `keepdim`.\n",
        "\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels, height, width)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        # Calculating mean and var over all dims except for the channel dim\n",
        "        if self.training:\n",
        "            # Take mean over all dimensions except the feature dimension\n",
        "            # Using keepdim=True so we don't have to worry about broadasting them with x at the end\n",
        "            mean = t.mean(x, dim=(0, 2, 3), keepdim=True)\n",
        "            var = t.var(x, dim=(0, 2, 3), unbiased=False, keepdim=True)\n",
        "            # Updating running mean and variance, in line with PyTorch documentation\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.squeeze()\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var.squeeze()\n",
        "            self.num_batches_tracked += 1\n",
        "        else:\n",
        "            mean = einops.rearrange(self.running_mean, \"channels -> 1 channels 1 1\")\n",
        "            var = einops.rearrange(self.running_var, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "        # Rearranging these so they can be broadcasted (although there are other ways you could do this)\n",
        "        weight = einops.rearrange(self.weight, \"channels -> 1 channels 1 1\")\n",
        "        bias = einops.rearrange(self.bias, \"channels -> 1 channels 1 1\")\n",
        "\n",
        "        return ((x - mean) / t.sqrt(var + self.eps)) * weight + bias\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        # SOLUTION\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in [\"num_features\", \"eps\", \"momentum\"]])\n",
        "\n",
        "```\n",
        "</details>\n",
        "\n",
        "## AveragePool\n",
        "\n",
        "Let's end our collection of `nn.Module`s with an easy one 🙂\n",
        "\n",
        "The ResNet has a Linear layer with 1000 outputs at the end in order to produce classification logits for each of the 1000 classes. Any Linear needs to have a constant number of input features, but the ResNet is supposed to be compatible with arbitrary height and width, so we can't just do a pooling operation with a fixed kernel size and stride.\n",
        "\n",
        "Luckily, the simplest possible solution works decently: take the mean over the spatial dimensions. Intuitively, each position has an equal \"vote\" for what objects it can \"see\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIirsi-0_uOk"
      },
      "source": [
        "### Exercise - implement `AveragePool`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴⚪⚪⚪⚪\n",
        "Importance: 🔵🔵⚪⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "This should be a pretty straightforward implementation; it doesn't have any weights or parameters of any kind, so you only need to implement the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrSwTHMi_v2B"
      },
      "outputs": [],
      "source": [
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        '''\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgL5nJrD_yD6"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AveragePool(nn.Module):\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, channels)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        return t.mean(x, dim=(2, 3))\n",
        "\n",
        "```\n",
        "</details>\n",
        "\n",
        "## Building ResNet\n",
        "\n",
        "Now we have all the building blocks we need to start assembling your own ResNet! The following diagram describes the architecture of ResNet34 - the other versions are broadly similar. Unless otherwise noted, convolutions have a kernel_size of 3x3, a stride of 1, and a padding of 1. None of the convolutions have biases.\n",
        "\n",
        "<details>\n",
        "<summary>Question: there would be no advantage to enabling biases on the convolutional layers. Why?</summary>\n",
        "\n",
        "Every convolution layer in this network is followed by a batch normalization layer. The first operation in the batch normalization layer is to subtract the mean of each output channel. But a convolutional bias just adds some scalar `b` to each output channel, increasing the mean by `b`. This means that for any `b` added, the batch normalization will subtract `b` to exactly negate the bias term.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question: why is it necessary for the output of the left and right computational tracks in ResidualBlock to be the same shape?</summary>\n",
        "\n",
        "Because they're added together at the end of the tracks. If they weren't the same shape, then they couldn't be added together.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about how the nested subgraphs work.</summary>\n",
        "\n",
        "The right-most block in the diagram, `ResidualBlock`, is nested inside `BlockGroup` multiple times. When you see `ResidualBlock` in `BlockGroup`, you should visualise a copy of `ResidualBlock` sitting in that position.\n",
        "    \n",
        "Similarly, `BlockGroup` is nested multiple times (four to be precise) in the full `ResNet34` architecture.\n",
        "</details>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/resnet-fixed.svg\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPuBVH3I_3gr"
      },
      "source": [
        "### Exercise - implement `ResidualBlock`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 15-30 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Implement `ResidualBlock` by referring to the diagram.  A few more notes on the left and right branches of this diagram:\n",
        "\n",
        "#### Left branch\n",
        "\n",
        "This branch has 2 convolutional layers. One of them applies a stride (the `first_stride` argument below), and changes the number of features from `in_feats -> out_feats`. The second one is a shape-preserving convolution, i.e. it has stride 1 and changes the number of features from `out_feats -> out_feats`.\n",
        "\n",
        "#### Right branch\n",
        "\n",
        "You can think of this branch as essentially a skip connection. But remember, we need to add this branch's output onto the left branch's output at the end of the residual block. If the left branch doesn't change the shape of its inputs (i.e. no strides, and `in_feats == out_feats`) then we can just use the identity operator for this right branch (you can use `nn.Identity` for this). But if either we have strides or a different number of output features, then we can't use the identity for the right branch. Instead we use what is essentially the closest approximation to the identity - a 1x1 convolution with stride & channel arguments chosen to match the shape of the left branch (followed by a batchnorm to standardize the output). Note, you may assume that if `first_stride == 1` then we always have number of input features equal to number of output features (meaning you can use the identity operator for this branch if and only if `first_stride == 1`).\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm completely stuck on parts of the architecture.</summary>\n",
        "\n",
        "In this case, you can use the following code to import your own `resnet34`, and inspect its architecture:\n",
        "\n",
        "```python\n",
        "resnet = models.resnet34()\n",
        "print(torchinfo.summary(resnet, input_size=(1, 3, 64, 64)))\n",
        "```\n",
        "\n",
        "This will generate output telling you the names of each module, as well as the parameter counts.\n",
        "\n",
        "Unfortunately, this function won't work on your own model if your model breaks when an image is passed through. Since a lot of the time mistakes in the architecture will mean your model doesn't work, you won't be able to use `torchinfo.summary` on your model. Instead, you should compare the models by printing them out.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chmn1EIj_41m"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "\n",
        "test_residual_block(ResidualBlock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQSt4TVg_7LS"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''\n",
        "        A single residual block with optional downsampling.\n",
        "\n",
        "        For compatibility with the pretrained model, declare the left side branch first using a `Sequential`.\n",
        "\n",
        "        If first_stride is > 1, this means the optional (conv + bn) should be present on the right branch. Declare it second using another `Sequential`.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "\n",
        "        self.left = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(out_feats)\n",
        "        )\n",
        "\n",
        "        if first_stride > 1:\n",
        "            self.right = Sequential(\n",
        "                Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride),\n",
        "                BatchNorm2d(out_feats)\n",
        "            )\n",
        "        else:\n",
        "            assert in_feats == out_feats\n",
        "            self.right = nn.Identity()\n",
        "\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / stride, width / stride)\n",
        "\n",
        "        If no downsampling block is present, the addition should just add the left branch's output to the input.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        x_left = self.left(x)\n",
        "        x_right = self.right(x)\n",
        "        return self.relu(x_left + x_right)\n",
        "```\n",
        "</details>\n",
        "\n",
        "### Exercise - implement `BlockGroup`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Implement `BlockGroup` according to the diagram.\n",
        "\n",
        "The number of channels changes from `in_feats` to `out_feats` in the first `ResidualBlock` (all subsequent blocks will have `out_feats` input channels and `out_feats` output channels).\n",
        "\n",
        "The `height` and `width` of the input will only be changed if `first_stride>1` (in which case it will be downsampled by exactly this amount).\n",
        "\n",
        "You can also read the docstring for a description of the input and output shapes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKFjfm06_8Wp"
      },
      "outputs": [],
      "source": [
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.'''\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "\n",
        "test_block_group(BlockGroup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940asI-B_-9i"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class BlockGroup(nn.Module):\n",
        "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
        "        '''An n_blocks-long sequence of ResidualBlock where only the first block uses the provided stride.'''\n",
        "        super().__init__()\n",
        "        # SOLUTION\n",
        "\n",
        "        blocks = [ResidualBlock(in_feats, out_feats, first_stride)] + [\n",
        "            ResidualBlock(out_feats, out_feats) for n in range(n_blocks - 1)\n",
        "        ]\n",
        "        self.blocks = Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        Compute the forward pass.\n",
        "\n",
        "        x: shape (batch, in_feats, height, width)\n",
        "\n",
        "        Return: shape (batch, out_feats, height / first_stride, width / first_stride)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        return self.blocks(x)\n",
        "\n",
        "```\n",
        "</details>\n",
        "\n",
        "### Exercise - implement `ResNet34`\n",
        "\n",
        "```yaml\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 25-30 minutes on this exercise.\n",
        "\n",
        "You may have to return to this and previous exercises, if you find a bug later.\n",
        "```\n",
        "\n",
        "Last step! Assemble `ResNet34` using the diagram.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to construct each of the BlockGroups.</summary>\n",
        "\n",
        "Each BlockGroup takes arguments `n_blocks`, `in_feats`, `out_feats` and `first_stride`. In the initialisation of `ResNet34` below, we're given a list of `n_blocks`, `out_feats` and `first_stride` for each of the BlockGroups. To find `in_feats` for each block, it suffices to note two things:\n",
        "    \n",
        "1. The first `in_feats` should be 64, because the input is coming from the convolutional layer with 64 output channels.\n",
        "2. The `out_feats` of each layer should be equal to the `in_feats` of the subsequent layer (because the BlockGroups are stacked one after the other; with no operations in between to change the shape).\n",
        "\n",
        "You can use these two facts to construct a list `in_features_per_group`, and then create your BlockGroups by zipping through all four lists.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to construct the 7x7 conv at the very start.</summary>\n",
        "\n",
        "All the information about this convolution is given in the diagram, except for `in_channels`. Recall that the input to this layer is an RGB image. Can you deduce from this how many input channels your layer should have?\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD2tSK1HAAIN"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "\n",
        "my_resnet = ResNet34()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFyxZEj_ADHI"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_blocks_per_group=[3, 4, 6, 3],\n",
        "        out_features_per_group=[64, 128, 256, 512],\n",
        "        first_strides_per_group=[1, 2, 2, 2],\n",
        "        n_classes=1000,\n",
        "    ):\n",
        "        # SOLUTION\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.n_blocks_per_group = n_blocks_per_group\n",
        "        self.out_features_per_group = out_features_per_group\n",
        "        self.first_strides_per_group = first_strides_per_group\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_layers = Sequential(\n",
        "            Conv2d(3, in_feats0, kernel_size=7, stride=2, padding=3),\n",
        "            BatchNorm2d(in_feats0),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        all_in_feats = [in_feats0] + out_features_per_group[:-1]\n",
        "        self.residual_layers = Sequential(\n",
        "            *(\n",
        "                BlockGroup(*args)\n",
        "                for args in zip(\n",
        "                    n_blocks_per_group,\n",
        "                    all_in_feats,\n",
        "                    out_features_per_group,\n",
        "                    first_strides_per_group,\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.out_layers = Sequential(\n",
        "            AveragePool(),\n",
        "            Linear(out_features_per_group[-1], n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, channels, height, width)\n",
        "        Return: shape (batch, n_classes)\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        x = self.in_layers(x)\n",
        "        x = self.residual_layers(x)\n",
        "        x = self.out_layers(x)\n",
        "        return x\n",
        "```\n",
        "</details>\n",
        "\n",
        "Now that you've built your `ResNet34`, we'll copy weights over from PyTorch's pretrained resnet to yours. This is a good way to verify that you've designed the architecture correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFiExIYeAEXh"
      },
      "outputs": [],
      "source": [
        "def copy_weights(my_resnet: ResNet34, pretrained_resnet: models.resnet.ResNet) -> ResNet34:\n",
        "    '''Copy over the weights of `pretrained_resnet` to your resnet.'''\n",
        "\n",
        "    # Get the state dictionaries for each model, check they have the same number of parameters & buffers\n",
        "    mydict = my_resnet.state_dict()\n",
        "    pretraineddict = pretrained_resnet.state_dict()\n",
        "    assert len(mydict) == len(pretraineddict), \"Mismatching state dictionaries.\"\n",
        "\n",
        "    # Define a dictionary mapping the names of your parameters / buffers to their values in the pretrained model\n",
        "    state_dict_to_load = {\n",
        "        mykey: pretrainedvalue\n",
        "        for (mykey, myvalue), (pretrainedkey, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())\n",
        "    }\n",
        "\n",
        "    # Load in this dictionary to your model\n",
        "    my_resnet.load_state_dict(state_dict_to_load)\n",
        "\n",
        "    return my_resnet\n",
        "\n",
        "\n",
        "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "my_resnet = copy_weights(my_resnet, pretrained_resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4SqVsqoAFi2"
      },
      "source": [
        "This function uses the `state_dict()` method, which returns an  `OrderedDict` (documentation [here](https://realpython.com/python-ordereddict/)) object containing all the parameter/buffer names and their values. State dicts can be extracted from models, saved to your filesystem (this is a common way to store the results of training a model), and can also be loaded back into a model using the `load_state_dict` method. (Note that you can also load weights using a regular Python `dict`, but since Python 3.7, the builtin `dict` is guaranteed to maintain items in the order they're inserted.)\n",
        "\n",
        "If the copying fails, this means that your model's layers don't match up with the layers in the PyTorch model implementation.\n",
        "\n",
        "To debug here, we've given you a helpful function `print_param_count` (from `utils.py`), which takes two models and prints out a stylized dataframe comparing the parameter names and shapes of each model. It will tell you when your model matches up with the PyTorch implementation. It can be used as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAAMfNwQTEEa"
      },
      "outputs": [],
      "source": [
        "print_param_count(my_resnet, pretrained_resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2olK_Yb6TDfI"
      },
      "source": [
        "You'll hopefully see something like the image below (the layer names not necessarily matching, but the parameter counts & shapes hopefully matching).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/Fundamentals/main/images/resnet-compared.png\" width=\"900\">\n",
        "\n",
        "Tweaking your model until all the layers match up might be a difficult and frustrating exercise at times! However, it's a pretty good example of the kind of low-level model implementation and debugging that is important for your growth as ML engineers. We'll be doing a few more model-building exercises similar to these in later sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdlj-azIAGzT"
      },
      "source": [
        "## Running Your Model\n",
        "\n",
        "We've provided you with some images for your model to classify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaK9CAV3AIG2"
      },
      "outputs": [],
      "source": [
        "IMAGE_FILENAMES = [\n",
        "    \"chimpanzee.jpg\",\n",
        "    \"golden_retriever.jpg\",\n",
        "    \"platypus.jpg\",\n",
        "    \"frogs.jpg\",\n",
        "    \"fireworks.jpg\",\n",
        "    \"astronaut.jpg\",\n",
        "    \"iguana.jpg\",\n",
        "    \"volcano.jpg\",\n",
        "    \"goofy.jpg\",\n",
        "    \"dragonfly.jpg\",\n",
        "]\n",
        "\n",
        "IMAGE_FOLDER = section_dir / \"resnet_inputs\"\n",
        "\n",
        "images = [Image.open(IMAGE_FOLDER / filename) for filename in IMAGE_FILENAMES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GL8fU67AJl3"
      },
      "source": [
        "Our `images` are of type `PIL.Image.Image`, so we can just call them in a cell to display them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a0wyprlAKMl"
      },
      "outputs": [],
      "source": [
        "images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKZX5btkALEZ"
      },
      "source": [
        "We now need to define a `transform` object like we did for MNIST. We will use the same transforms to convert the PIL image to a tensor, and to normalize it. But we also want to resize the images to `height=224, width=224`, because not all of them start out with this size and we need them to be consistent before passing them through our model.\n",
        "\n",
        "In the normalization step, we'll use a mean of `[0.485, 0.456, 0.406]`, and a standard deviation of `[0.229, 0.224, 0.225]` (these are the mean and std dev of images from [ImageNet](https://www.image-net.org/)). Note that the means and std devs have three elements, because ImageNet contains RGB rather than monochrome images, and we're normalising over each of the three RGB channels separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLAjqJp4AM2y"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMAGENET_TRANSFORM = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "prepared_images = t.stack([IMAGENET_TRANSFORM(img) for img in images], dim=0)\n",
        "\n",
        "assert prepared_images.shape == (len(images), 3, IMAGE_SIZE, IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "158B2_GpAMM-"
      },
      "source": [
        "### Exercise - verify your model's predictions\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Lastly, you should run your model with these prepared images, and verify that your predictions are the same as the model's predictions.\n",
        "\n",
        "You can do this by filling in the `predict` function below, then running the code. We've also provided you with a file `imagenet_labels.json` which you can use to get the actual classnames of imagenet data, and see what your model's predictions actually are.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpHmhQ_lAQrK"
      },
      "outputs": [],
      "source": [
        "def predict(model, images: t.Tensor) -> list[int]:\n",
        "    '''\n",
        "    Returns the predicted class for each image (as a list of ints).\n",
        "    '''\n",
        "    pass\n",
        "\n",
        "\n",
        "with open(section_dir / \"imagenet_labels.json\") as f:\n",
        "    imagenet_labels = list(json.load(f).values())\n",
        "\n",
        "# Check your predictions match those of the pretrained model\n",
        "my_predictions = predict(my_resnet, prepared_images)\n",
        "pretrained_predictions = predict(pretrained_resnet, prepared_images)\n",
        "assert all(my_predictions == pretrained_predictions)\n",
        "print(\"All predictions match!\")\n",
        "\n",
        "# Print out your predictions, next to the corresponding images\n",
        "for img, label in zip(images, my_predictions):\n",
        "    print(f\"Class {label}: {imagenet_labels[label]}\")\n",
        "    display(img)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "def predict(model, images: t.Tensor) -> list[int]:\n",
        "    '''\n",
        "    Returns the predicted class for each image (as a list of ints).\n",
        "    '''\n",
        "    logits: t.Tensor = model(images)\n",
        "    return logits.argmax(dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kRkih3iAS85"
      },
      "source": [
        "If you've done everything correctly, your version should give the same classifications, and the percentages should match at least to a couple decimal places.\n",
        "\n",
        "If it does, congratulations, you've now run an entire ResNet, using barely any code from `torch.nn`! The only things we used were `nn.Module` and `nn.Parameter`.\n",
        "\n",
        "If it doesn't, you get to practice model debugging! Remember to use the `utils.print_param_count` function that was provided.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Help! My model is predicting roughly the same percentage for every category!</summary>\n",
        "\n",
        "This can indicate that your model weights are randomly initialized, meaning the weight loading process didn't actually take. Or, you reinitialized your model by accident after loading the weights.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jd3LpCav3UXu",
        "cmgIafL_7EUG",
        "59YGDI3p7FdX",
        "DiUVKtaD7HuH",
        "a9NImreY7IZb",
        "s14T6NUJ7Ivu",
        "eXGCrNHa7ek0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
